import os
import sys
from typing import List

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix
from sklearn.model_selection import train_test_split
import joblib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from backend.config import (
    DATA_PATH,
    TEST_SIZE,
    RANDOM_STATE,
    THRESH_START,
    THRESH_END,
    THRESH_STEP,
)
from backend.models import get_model


# ì‹œë®¬ë ˆì´í„°ìš© 6ê°œ í”¼ì²˜
SIM_FEATURES: List[str] = [
    "app_crash_count_30d",
    "skip_rate_increase_7d",
    "days_since_last_login",
    "listening_time_trend_7d",
    "freq_of_use_trend_14d",
    "login_frequency_30d",
]

# ë‹¨ì¡° ì œì•½ ë°©í–¥
#  +1: ê°’ì´ ì¦ê°€í• ìˆ˜ë¡ ì´íƒˆ í™•ë¥ ì´ "ì¦ê°€"í•´ì•¼ í•¨
#  -1: ê°’ì´ ì¦ê°€í• ìˆ˜ë¡ ì´íƒˆ í™•ë¥ ì´ "ê°ì†Œ"í•´ì•¼ í•¨
MONO_CONSTRAINTS = [
    +1,  # app_crash_count_30d        (í¬ë˜ì‹œ ë§ì„ìˆ˜ë¡ ìœ„í—˜ â†‘)
    +1,  # skip_rate_increase_7d      (ìŠ¤í‚µë¥  ì¦ê°€í• ìˆ˜ë¡ ìœ„í—˜ â†‘)
    +1,  # days_since_last_login      (ì˜¤ë˜ ì•ˆ ë“¤ì–´ì˜¬ìˆ˜ë¡ ìœ„í—˜ â†‘)
    -1,  # listening_time_trend_7d    (ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ì‚¬ìš©ëŸ‰ ì¦ê°€ â†’ ìœ„í—˜ â†“)
    -1,  # freq_of_use_trend_14d      (ì‚¬ìš© ë¹ˆë„ ì¦ê°€ â†’ ìœ„í—˜ â†“)
    -1,  # login_frequency_30d        (ë¡œê·¸ì¸ ìì£¼ í• ìˆ˜ë¡ ìœ„í—˜ â†“)
]


def main() -> None:
    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}")

    df = pd.read_csv(DATA_PATH)
    if "is_churned" not in df.columns:
        raise ValueError("'is_churned' íƒ€ê¹ƒ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
    print(f"   ì´íƒˆë¥ : {df['is_churned'].mean():.2%}")

    X = df[SIM_FEATURES].copy()
    y = df["is_churned"].astype(int).values

    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=TEST_SIZE,
        random_state=RANDOM_STATE,
        stratify=y,
    )

    print("\nğŸ”§ 6í”¼ì²˜ ì „ìš© LGBM(ë‹¨ì¡° ì œì•½) ê¸°ë³¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

    # ê¸°ë³¸ ëª¨ë¸ - ë‹¨ì¡° ì œì•½ë§Œ ì ìš©
    model = get_model(
        name="lgbm",
        random_state=RANDOM_STATE,
        monotone_constraints=MONO_CONSTRAINTS,
    )
    model.fit(X_train, y_train)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")

    y_proba = model.predict_proba(X_test)[:, 1]
    auc = roc_auc_score(y_test, y_proba)

    thresholds = np.arange(THRESH_START, THRESH_END, THRESH_STEP)
    best_f1 = 0.0
    best_th = 0.5

    for th in thresholds:
        y_pred = (y_proba >= th).astype(int)
        f1 = f1_score(y_test, y_pred)
        if f1 > best_f1:
            best_f1 = f1
            best_th = float(th)

    y_best = (y_proba >= best_th).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_test, y_best).ravel()

    print("\n" + "=" * 70)
    print("ğŸ“Š 6í”¼ì²˜ ì „ìš© LGBM(ë‹¨ì¡° ì œì•½) ê¸°ë³¸ ëª¨ë¸ ì„±ëŠ¥ (ê²€ì¦ ì„¸íŠ¸ ê¸°ì¤€)")
    print("=" * 70)
    print(f"ROC-AUC        : {auc:.4f}")
    print(f"Best F1        : {best_f1:.4f}")
    print(f"Best Threshold : {best_th:.2f}")
    print(f"TN={tn}, FP={fp}, FN={fn}, TP={tp}")
    print("=" * 70)

    os.makedirs("models", exist_ok=True)
    out_path = os.path.join("models", "lgbm_sim_6feat_mono_v1_baseline.pkl")
    joblib.dump(model, out_path)
    print(f"\nğŸ’¾ 6í”¼ì²˜ ì „ìš© LGBM(ë‹¨ì¡° ì œì•½) ê¸°ë³¸ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {out_path}")
    print("   (v1 ê¸°ë³¸ ë²„ì „ - ë‹¨ì¡° ì œì•½ë§Œ ì ìš©)")


if __name__ == "__main__":
    main()
