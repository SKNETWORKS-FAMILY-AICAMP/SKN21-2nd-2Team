{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14d4e56",
   "metadata": {},
   "source": [
    "# Feature Selection with Categorical Features\n",
    "\n",
    "이 노트북은 **수치형 + FE + 범주형(원-핫 인코딩)** 을 모두 포함했을 때\n",
    "F1 / AUC가 어떻게 달라지는지 다시 검증하는 용도입니다.\n",
    "\n",
    "- 입력 데이터: `../data/raw_data.csv`\n",
    "- 기준: `FE_validation.ipynb`에서 정리된 **base_num + 핵심 FE 세트**를 재사용\n",
    "- 추가: `gender`, `country`, `subscription_type`, `device_type` 등 **범주형을 One-Hot 인코딩**해서 포함\n",
    "\n",
    "여기서 얻고 싶은 것:\n",
    "- **수치형 + FE만 쓴 경우 vs 수치형 + FE + 범주형까지 쓴 경우**의 F1 / AUC 비교\n",
    "- 범주형이 실제로 **성능에 얼마나 기여하는지**를 수치로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526044e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape = (8000, 12)\n",
      "Index(['user_id', 'gender', 'age', 'country', 'subscription_type',\n",
      "       'listening_time', 'songs_played_per_day', 'skip_rate', 'device_type',\n",
      "       'ads_listened_per_week', 'offline_listening', 'is_churned'],\n",
      "      dtype='object')\n",
      "\n",
      "FE 생성 후 컬럼 예시:\n",
      "Index(['user_id', 'gender', 'age', 'country', 'subscription_type',\n",
      "       'listening_time', 'songs_played_per_day', 'skip_rate', 'device_type',\n",
      "       'ads_listened_per_week', 'offline_listening', 'is_churned',\n",
      "       'engagement_score', 'listening_time_bin', 'skip_rate_cap',\n",
      "       'ads_pressure', 'songs_per_minute', 'skip_intensity',\n",
      "       'subscription_type_level', 'age_group', 'ads_listened_log'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 로드 및 FE 생성 (FE_validation.ipynb 로직 재사용 버전)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "DATA_PATH = \"../data/raw_data.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"df shape =\", df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "# 수치형 기본 컬럼 (base_num)\n",
    "BASE_NUM_COLS = [\n",
    "    \"age\",\n",
    "    \"listening_time\",\n",
    "    \"songs_played_per_day\",\n",
    "    \"skip_rate\",\n",
    "    \"ads_listened_per_week\",\n",
    "    \"offline_listening\",\n",
    "]\n",
    "\n",
    "# 원본 범주형 컬럼\n",
    "RAW_CAT_COLS = [\n",
    "    \"gender\",\n",
    "    \"country\",\n",
    "    \"subscription_type\",\n",
    "    \"device_type\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_fe_dataframe_full() -> pd.DataFrame:\n",
    "    \"\"\"FE_validation.ipynb에서 사용한 FE들을 통합 생성하는 함수\n",
    "    - 결측치 median 처리 (수치형)\n",
    "    - FE 4개: engagement_score, listening_time_bin, skip_rate_cap, ads_pressure\n",
    "    - 추가 FE: songs_per_minute, skip_intensity\n",
    "    - 추가 범주형 기반 FE: subscription_type_level, age_group, ads_listened_log\n",
    "    (원본 범주형 컬럼은 그대로 유지해서 나중에 One-Hot 인코딩에 사용)\n",
    "    \"\"\"\n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    # 1) 수치형 결측치 median 처리\n",
    "    for c in BASE_NUM_COLS:\n",
    "        if c in df_tmp.columns and df_tmp[c].isnull().any():\n",
    "            df_tmp[c] = df_tmp[c].fillna(df_tmp[c].median())\n",
    "\n",
    "    # 2) FE 4개 생성 (engagement_score, listening_time_bin, skip_rate_cap, ads_pressure)\n",
    "    # 2-1) engagement_score\n",
    "    if {\"listening_time\", \"songs_played_per_day\"}.issubset(df_tmp.columns):\n",
    "        df_tmp[\"engagement_score\"] = (\n",
    "            df_tmp[\"listening_time\"] * df_tmp[\"songs_played_per_day\"]\n",
    "        )\n",
    "\n",
    "    # 2-2) listening_time_bin\n",
    "    if \"listening_time\" in df_tmp.columns:\n",
    "        try:\n",
    "            df_tmp[\"listening_time_bin\"] = pd.qcut(\n",
    "                df_tmp[\"listening_time\"], 3, labels=[\"low\", \"mid\", \"high\"]\n",
    "            )\n",
    "        except Exception:\n",
    "            bins = [0, 60, 180, df_tmp[\"listening_time\"].max()]\n",
    "            df_tmp[\"listening_time_bin\"] = pd.cut(\n",
    "                df_tmp[\"listening_time\"],\n",
    "                bins=bins,\n",
    "                labels=[\"low\", \"mid\", \"high\"],\n",
    "                include_lowest=True,\n",
    "            )\n",
    "\n",
    "    # 2-3) skip_rate_cap\n",
    "    if \"skip_rate\" in df_tmp.columns:\n",
    "        df_tmp[\"skip_rate_cap\"] = df_tmp[\"skip_rate\"].clip(lower=0, upper=1.5)\n",
    "\n",
    "    # 2-4) ads_pressure\n",
    "    if {\"ads_listened_per_week\", \"listening_time\"}.issubset(df_tmp.columns):\n",
    "        lt_nonzero = df_tmp[\"listening_time\"].replace(0, np.nan)\n",
    "        df_tmp[\"ads_pressure\"] = df_tmp[\"ads_listened_per_week\"] / lt_nonzero\n",
    "\n",
    "    # 3) 추가 FE: songs_per_minute, skip_intensity (Set D 기준)\n",
    "    lt_safe = df_tmp[\"listening_time\"].replace(0, np.nan)\n",
    "    df_tmp[\"songs_per_minute\"] = (\n",
    "        df_tmp[\"songs_played_per_day\"] / lt_safe\n",
    "    ).fillna(0.0)\n",
    "    df_tmp[\"skip_intensity\"] = df_tmp[\"skip_rate\"] * df_tmp[\"songs_played_per_day\"]\n",
    "\n",
    "    # 4) 범주형 기반 FE (v3 기준)\n",
    "    # 4-1) subscription_type_level (순서형 매핑)\n",
    "    if \"subscription_type\" in df_tmp.columns:\n",
    "        level_map = {\n",
    "            \"Free\": 0,\n",
    "            \"Student\": 1,\n",
    "            \"Premium\": 2,\n",
    "            \"Family\": 3,\n",
    "        }\n",
    "        df_tmp[\"subscription_type_level\"] = (\n",
    "            df_tmp[\"subscription_type\"].map(level_map).fillna(-1).astype(int)\n",
    "        )\n",
    "\n",
    "    # 4-2) age_group (카테고리 구간)\n",
    "    if \"age\" in df_tmp.columns:\n",
    "        bins = [0, 24, 34, 44, df_tmp[\"age\"].max()]\n",
    "        labels = [\"young\", \"adult\", \"middle\", \"senior\"]\n",
    "        df_tmp[\"age_group\"] = pd.cut(\n",
    "            df_tmp[\"age\"],\n",
    "            bins=bins,\n",
    "            labels=labels,\n",
    "            include_lowest=True,\n",
    "            right=True,\n",
    "        )\n",
    "\n",
    "    # 4-3) ads_listened_log (로그 변환)\n",
    "    if \"ads_listened_per_week\" in df_tmp.columns:\n",
    "        df_tmp[\"ads_listened_log\"] = np.log1p(df_tmp[\"ads_listened_per_week\"])\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "df_fe = make_fe_dataframe_full()\n",
    "print(\"\\nFE 생성 후 컬럼 예시:\")\n",
    "print(df_fe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ea2f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot 인코딩 대상 범주형 컬럼: ['gender', 'country', 'subscription_type', 'device_type', 'listening_time_bin', 'age_group']\n",
      "X_num_only shape: (8000, 10)\n",
      "X_all shape: (8000, 31)\n",
      "\n",
      "=== RF + best F1 기준 성능 비교 (수치형 vs 수치형+범주형) ===\n",
      "[Numeric only]   best F1 = 0.4127 @ th=0.10, AUC = 0.5289\n",
      "[Numeric + cat] best F1 = 0.4113 @ th=0.10, AUC = 0.5117\n"
     ]
    }
   ],
   "source": [
    "# 2. 수치형만 vs 수치형+FE+범주형(One-Hot) F1 / AUC 비교\n",
    "\n",
    "# (1) 타깃 정의\n",
    "y = df_fe[\"is_churned\"]\n",
    "\n",
    "# (2) 수치형 + 핵심 FE 세트 (기존 Set D / 추천 세트 기반)\n",
    "NUM_FE_COLS = [\n",
    "    \"engagement_score\",\n",
    "    \"songs_per_minute\",\n",
    "    \"skip_intensity\",\n",
    "    \"skip_rate_cap\",\n",
    "]\n",
    "\n",
    "# ads_pressure, ads_listened_log 정도는 보조로 추가해도 크게 문제 없음\n",
    "OPTIONAL_FE_COLS = [\n",
    "    \"ads_pressure\",\n",
    "    \"ads_listened_log\",\n",
    "]\n",
    "\n",
    "num_cols_exist = [c for c in BASE_NUM_COLS if c in df_fe.columns]\n",
    "num_fe_exist = [c for c in NUM_FE_COLS if c in df_fe.columns]\n",
    "opt_fe_exist = [c for c in OPTIONAL_FE_COLS if c in df_fe.columns]\n",
    "\n",
    "X_num_only = df_fe[num_cols_exist + num_fe_exist]  # 기존 우리가 주로 쓰던 세트와 유사\n",
    "\n",
    "# (3) 범주형 + 구간형 컬럼들 One-Hot 인코딩\n",
    "cat_cols = []\n",
    "\n",
    "# 원본 범주형\n",
    "for c in RAW_CAT_COLS:\n",
    "    if c in df_fe.columns:\n",
    "        cat_cols.append(c)\n",
    "\n",
    "# 파생 범주형(listening_time_bin, age_group)\n",
    "for c in [\"listening_time_bin\", \"age_group\"]:\n",
    "    if c in df_fe.columns:\n",
    "        cat_cols.append(c)\n",
    "\n",
    "print(\"\\nOne-Hot 인코딩 대상 범주형 컬럼:\", cat_cols)\n",
    "\n",
    "if cat_cols:\n",
    "    X_cat = pd.get_dummies(df_fe[cat_cols], drop_first=True)\n",
    "else:\n",
    "    X_cat = pd.DataFrame(index=df_fe.index)\n",
    "\n",
    "# 수치형 + FE + 범주형 모두 포함한 세트\n",
    "X_all = pd.concat([X_num_only, df_fe[opt_fe_exist], X_cat], axis=1)\n",
    "\n",
    "print(\"X_num_only shape:\", X_num_only.shape)\n",
    "print(\"X_all shape:\", X_all.shape)\n",
    "\n",
    "\n",
    "def evaluate_rf_best_f1(X, y, thresholds=None):\n",
    "    \"\"\"RandomForest + threshold 튜닝으로 best F1 / AUC 계산\"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0.1, 0.9, 17)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = rf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_th = 0.5\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_proba >= th).astype(int)\n",
    "        f1 = f1_score(y_valid, y_pred_th)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = th\n",
    "\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    return best_f1, best_th, auc\n",
    "\n",
    "\n",
    "print(\"\\n=== RF + best F1 기준 성능 비교 (수치형 vs 수치형+범주형) ===\")\n",
    "\n",
    "best_f1_num, best_th_num, auc_num = evaluate_rf_best_f1(X_num_only, y)\n",
    "print(\"[Numeric only]   best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_num, best_th_num, auc_num))\n",
    "\n",
    "best_f1_all, best_th_all, auc_all = evaluate_rf_best_f1(X_all, y)\n",
    "print(\"[Numeric + cat] best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_all, best_th_all, auc_all))\n",
    "\n",
    "# (선택) 중요도 상위 몇 개만 확인해보고 싶으면 아래 주석을 풀어서 사용\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "#     X_all, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "# rf_all = RandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     max_depth=None,\n",
    "#     min_samples_split=5,\n",
    "#     class_weight=\"balanced\",\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42,\n",
    "# )\n",
    "# rf_all.fit(X_train, y_train)\n",
    "# importances = rf_all.feature_importances_\n",
    "# feat_names = X_all.columns\n",
    "# imp_df = pd.DataFrame({\"feature\": feat_names, \"importance\": importances}).sort_values(\n",
    "#     \"importance\", ascending=False\n",
    "# )\n",
    "# imp_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41407ba5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. K-Fold 기반 RF + Threshold 튜닝 (수치형 + FE 기준)\n",
    "\n",
    "여기서는 **수치형 + 핵심 FE 세트(`X_num_only`)**를 기준으로,\n",
    "K-Fold 교차검증으로 threshold까지 튜닝한 **보다 안정적인 F1/AUC**를 계산합니다.\n",
    "\n",
    "- 모델: `RandomForestClassifier(class_weight=\"balanced\")`\n",
    "- CV: `StratifiedKFold(n_splits=5)`\n",
    "- Threshold 탐색: 0.05 ~ 0.35 구간에서 0.01 간격\n",
    "\n",
    "이 결과가 사실상 **이 데이터에서 낼 수 있는 상한선에 어느 정도 근접한 F1**이라고 보면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1015b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RF (Numeric + 핵심 FE, K-Fold 기반) ===\n",
      "best F1 (CV) = 0.4120 @ th=0.11, AUC (CV) = 0.5280\n"
     ]
    }
   ],
   "source": [
    "# 3-1. K-Fold 기반 RF + threshold 튜닝 함수 정의\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def evaluate_model_cv_best_f1(model, X, y, thresholds=None, n_splits=5):\n",
    "    \"\"\"아무 분류 모델이나 받아서, K-Fold CV 기반으로 best F1 / AUC 계산\n",
    "    - model: scikit-learn 분류기 (fit/predict_proba 지원)\n",
    "    - thresholds: 탐색할 threshold 리스트 (None이면 0.05~0.35, step=0.01)\n",
    "    - n_splits: StratifiedKFold 분할 개수\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.round(np.arange(0.05, 0.36, 0.01), 2)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_score = []\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "        X_tr, X_vl = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_tr, y_vl = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        mdl = model  # 원본 모델을 그대로 쓰면 fold 간 누적 학습 위험 → clone 사용 권장\n",
    "        from sklearn.base import clone\n",
    "\n",
    "        mdl = clone(model)\n",
    "        mdl.fit(X_tr, y_tr)\n",
    "\n",
    "        y_proba = mdl.predict_proba(X_vl)[:, 1]\n",
    "\n",
    "        all_y_true.append(y_vl)\n",
    "        all_y_score.append(y_proba)\n",
    "\n",
    "    all_y_true = np.concatenate([arr.values if hasattr(arr, \"values\") else arr for arr in all_y_true])\n",
    "    all_y_score = np.concatenate(all_y_score)\n",
    "\n",
    "    # threshold별 F1 측정\n",
    "    best_f1 = 0.0\n",
    "    best_th = 0.5\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (all_y_score >= th).astype(int)\n",
    "        f1 = f1_score(all_y_true, y_pred_th)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = float(th)\n",
    "\n",
    "    auc = roc_auc_score(all_y_true, all_y_score)\n",
    "    return best_f1, best_th, auc\n",
    "\n",
    "\n",
    "# 3-2. 기본 RF 모델로 CV 기반 best F1 / AUC 계산 (수치형 + 핵심 FE 기준)\n",
    "\n",
    "base_rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "best_f1_cv, best_th_cv, auc_cv = evaluate_model_cv_best_f1(base_rf, X_num_only, y)\n",
    "\n",
    "print(\"=== RF (Numeric + 핵심 FE, K-Fold 기반) ===\")\n",
    "print(\"best F1 (CV) = {:.4f} @ th={:.2f}, AUC (CV) = {:.4f}\".format(best_f1_cv, best_th_cv, auc_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9361e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. RandomizedSearchCV로 RF 하이퍼파라미터 튜닝\n",
    "\n",
    "이제 같은 `X_num_only`(수치형 + 핵심 FE)에 대해 **RF 하이퍼파라미터를 랜덤 탐색**으로 튜닝합니다.\n",
    "\n",
    "- 튜닝 대상:\n",
    "  - `n_estimators`: [200, 300, 400, 500, 600]\n",
    "  - `max_depth`: [3, 5, 7, None]\n",
    "  - `min_samples_split`: [2, 5, 10]\n",
    "  - `min_samples_leaf`: [1, 2, 5]\n",
    "  - `max_features`: [\"sqrt\", \"log2\", 0.5]\n",
    "- CV: 3-Fold, scoring = `f1`\n",
    "\n",
    "튜닝된 RF를 다시 **K-Fold + threshold 튜닝**으로 평가해서,\n",
    "기본 RF 대비 F1/AUC가 얼마나 개선되는지 비교합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e694351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV (RF) fitting...\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "\n",
      "=== RF RandomizedSearchCV best params ===\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 3}\n",
      "best CV F1 (search scoring) = 0.3313\n",
      "\n",
      "=== Tuned RF (Numeric + 핵심 FE, K-Fold 기반) ===\n",
      "best F1 (CV) = 0.4113 @ th=0.05, AUC (CV) = 0.5071\n",
      "\n",
      "[비교] 기본 RF vs 튜닝 RF (둘 다 X_num_only 기준)\n",
      "- 기본 RF : F1 = 0.4120, AUC = 0.5280\n",
      "- 튜닝 RF : F1 = 0.4113, AUC = 0.5071\n"
     ]
    }
   ],
   "source": [
    "# 4-1. RF RandomizedSearchCV 수행\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_for_search = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 300, 400, 500, 600],\n",
    "    \"max_depth\": [3, 5, 7, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.5],\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf_for_search,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,  # 시간이 너무 오래 걸리면 15~20으로 줄여도 됨\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"RandomizedSearchCV (RF) fitting...\")\n",
    "rf_random.fit(X_num_only, y)\n",
    "\n",
    "print(\"\\n=== RF RandomizedSearchCV best params ===\")\n",
    "print(rf_random.best_params_)\n",
    "print(\"best CV F1 (search scoring) = {:.4f}\".format(rf_random.best_score_))\n",
    "\n",
    "# 4-2. 튜닝된 RF를 K-Fold + threshold 튜닝으로 재평가\n",
    "\n",
    "best_rf = rf_random.best_estimator_\n",
    "\n",
    "best_f1_cv_tuned, best_th_cv_tuned, auc_cv_tuned = evaluate_model_cv_best_f1(\n",
    "    best_rf, X_num_only, y\n",
    ")\n",
    "\n",
    "print(\"\\n=== Tuned RF (Numeric + 핵심 FE, K-Fold 기반) ===\")\n",
    "print(\n",
    "    \"best F1 (CV) = {:.4f} @ th={:.2f}, AUC (CV) = {:.4f}\".format(\n",
    "        best_f1_cv_tuned, best_th_cv_tuned, auc_cv_tuned\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n[비교] 기본 RF vs 튜닝 RF (둘 다 X_num_only 기준)\")\n",
    "print(\n",
    "    \"- 기본 RF : F1 = {:.4f}, AUC = {:.4f}\".format(\n",
    "        best_f1_cv, auc_cv\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"- 튜닝 RF : F1 = {:.4f}, AUC = {:.4f}\".format(\n",
    "        best_f1_cv_tuned, auc_cv_tuned\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd576479",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. (선택) 튜닝 RF + HGB + LR 간단 앙상블\n",
    "\n",
    "시간 여유가 있으면, 아래 셀로 **간단 소프트 보팅 앙상블**도 시도해 볼 수 있습니다.\n",
    "\n",
    "- 구성 예시:\n",
    "  - 튜닝된 RF (`best_rf`)\n",
    "  - `HistGradientBoostingClassifier`\n",
    "  - `LogisticRegression` (수치형 + FE만 사용)\n",
    "\n",
    "이 셀은 **필요할 때만 실행**해도 되고, 너무 무겁게 느껴지면 건너뛰어도 괜찮습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdceba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Soft Voting Ensemble (RF + HGB + LR, X_num_only) ===\n",
      "best F1 (CV) = 0.4113 @ th=0.29, AUC (CV) = 0.5169\n",
      "\n",
      "[비교] 기본 RF vs 튜닝 RF vs 앙상블\n",
      "- 기본 RF   : F1 = 0.4120, AUC = 0.5280\n",
      "- 튜닝 RF   : F1 = 0.4113, AUC = 0.5071\n",
      "- 앙상블 RF: F1 = 0.4113, AUC = 0.5169\n"
     ]
    }
   ],
   "source": [
    "# 5-1. 간단 소프트 보팅 앙상블 (선택 실행)\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# HGB / LR 기본 세팅 (필요하면 나중에 따로 튜닝 가능)\n",
    "hgb_clf = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "lr_clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# VotingClassifier 구성 (모두 X_num_only 기준)\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rf\", best_rf),\n",
    "        (\"hgb\", hgb_clf),\n",
    "        (\"lr\", lr_clf),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "best_f1_ens, best_th_ens, auc_ens = evaluate_model_cv_best_f1(\n",
    "    ensemble, X_num_only, y\n",
    ")\n",
    "\n",
    "print(\"=== Soft Voting Ensemble (RF + HGB + LR, X_num_only) ===\")\n",
    "print(\n",
    "    \"best F1 (CV) = {:.4f} @ th={:.2f}, AUC (CV) = {:.4f}\".format(\n",
    "        best_f1_ens, best_th_ens, auc_ens\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n[비교] 기본 RF vs 튜닝 RF vs 앙상블\")\n",
    "print(\"- 기본 RF   : F1 = {:.4f}, AUC = {:.4f}\".format(best_f1_cv, auc_cv))\n",
    "print(\"- 튜닝 RF   : F1 = {:.4f}, AUC = {:.4f}\".format(best_f1_cv_tuned, auc_cv_tuned))\n",
    "print(\"- 앙상블 RF: F1 = {:.4f}, AUC = {:.4f}\".format(best_f1_ens, auc_ens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ca131",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 피처별 이탈 영향도 분석 (왜 성능이 안 나오는지 원인 파악)\n",
    "\n",
    "지금까지 **모든 튜닝/FE/앙상블을 해도 F1이 0.41대에서 막혔다**는 것은,\n",
    "**데이터 자체의 한계** 때문일 가능성이 크다.\n",
    "\n",
    "여기서는 각 피처가 `is_churned`와 **실제로 얼마나 연관이 있는지**를 확인해서,\n",
    "**\"왜 성능이 안 올라가는가?\"**의 근본 원인을 찾아본다.\n",
    "\n",
    "### 분석 목표\n",
    "1. **수치형 피처**: 이탈 vs 비이탈 분포 비교 (박스플롯, t-test p-value)\n",
    "2. **범주형 피처**: 각 카테고리별 이탈률 차이\n",
    "3. **상관계수**: 피처 vs is_churned (Point-Biserial Correlation)\n",
    "4. **RF Feature Importance + Permutation Importance** (통합 확인)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da671933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 수치형 피처별 이탈 vs 비이탈 분포 비교 (t-test) ===\n",
      "\n",
      "              feature  mean_churned  mean_not_churned      diff    t_stat  p_value\n",
      "        skip_rate_cap      0.331378          0.320691  0.010687  1.726153 0.084408\n",
      "            skip_rate      0.368289          0.351054  0.017235  1.430528 0.152658\n",
      "    offline_listening      0.757122          0.744476  0.012646  1.149979 0.250227\n",
      " songs_played_per_day     50.617576         49.992073  0.625503  0.876739 0.380687\n",
      "       skip_intensity     18.404178         17.770269  0.633909  0.869820 0.384456\n",
      "       listening_time    153.174312        154.536347 -1.362035 -0.648440 0.516741\n",
      "     songs_per_minute      0.607387          0.595543  0.011844  0.499394 0.617533\n",
      "                  age     38.998551         38.811941  0.186610  0.418242 0.675795\n",
      "ads_listened_per_week      6.891357          6.962220 -0.070863 -0.202819 0.839288\n",
      "     engagement_score   7724.631579       7698.635689 25.995890  0.158765 0.873863\n",
      "\n",
      "▶ p-value < 0.05인 피처들만 이탈과 유의미한 차이가 있음\n",
      "▶ p-value가 크면 → 이탈 여부와 거의 무관 → 모델 성능에 기여 어려움\n"
     ]
    }
   ],
   "source": [
    "# 6-1. 수치형 피처: 이탈 vs 비이탈 분포 비교 (t-test p-value 포함)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# 수치형 기본 + 핵심 FE\n",
    "numeric_features = BASE_NUM_COLS + NUM_FE_COLS\n",
    "\n",
    "churned = df_fe[df_fe[\"is_churned\"] == 1]\n",
    "not_churned = df_fe[df_fe[\"is_churned\"] == 0]\n",
    "\n",
    "print(\"=== 수치형 피처별 이탈 vs 비이탈 분포 비교 (t-test) ===\\n\")\n",
    "\n",
    "ttest_results = []\n",
    "\n",
    "for col in numeric_features:\n",
    "    if col not in df_fe.columns:\n",
    "        continue\n",
    "    \n",
    "    # t-test 수행\n",
    "    val_churned = churned[col].dropna()\n",
    "    val_not_churned = not_churned[col].dropna()\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(val_churned, val_not_churned, equal_var=False)\n",
    "    \n",
    "    mean_churned = val_churned.mean()\n",
    "    mean_not_churned = val_not_churned.mean()\n",
    "    \n",
    "    ttest_results.append({\n",
    "        \"feature\": col,\n",
    "        \"mean_churned\": mean_churned,\n",
    "        \"mean_not_churned\": mean_not_churned,\n",
    "        \"diff\": mean_churned - mean_not_churned,\n",
    "        \"t_stat\": t_stat,\n",
    "        \"p_value\": p_val,\n",
    "    })\n",
    "\n",
    "ttest_df = pd.DataFrame(ttest_results).sort_values(\"p_value\")\n",
    "print(ttest_df.to_string(index=False))\n",
    "\n",
    "# p-value가 작을수록(< 0.05) 이탈과 유의미한 관계\n",
    "print(\"\\n▶ p-value < 0.05인 피처들만 이탈과 유의미한 차이가 있음\")\n",
    "print(\"▶ p-value가 크면 → 이탈 여부와 거의 무관 → 모델 성능에 기여 어려움\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed98acd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 범주형 피처별 이탈률 ===\n",
      "\n",
      "\n",
      "[gender]\n",
      "        churn_rate  count\n",
      "gender                   \n",
      "Female    0.262881   2659\n",
      "Other     0.261887   2650\n",
      "Male      0.251951   2691\n",
      "\n",
      "[country]\n",
      "         churn_rate  count\n",
      "country                   \n",
      "PK         0.275275    999\n",
      "DE         0.272906   1015\n",
      "FR         0.271992    989\n",
      "AU         0.257253   1034\n",
      "US         0.253876   1032\n",
      "CA         0.248428    954\n",
      "UK         0.247412    966\n",
      "IN         0.243323   1011\n",
      "\n",
      "[subscription_type]\n",
      "                   churn_rate  count\n",
      "subscription_type                   \n",
      "Family               0.275157   1908\n",
      "Student              0.261868   1959\n",
      "Premium              0.250591   2115\n",
      "Free                 0.249257   2018\n",
      "\n",
      "[device_type]\n",
      "             churn_rate  count\n",
      "device_type                   \n",
      "Mobile         0.268950   2599\n",
      "Desktop        0.257379   2778\n",
      "Web            0.250477   2623\n",
      "\n",
      "[listening_time_bin]\n",
      "                    churn_rate  count\n",
      "listening_time_bin                   \n",
      "low                   0.261567   2680\n",
      "mid                   0.260984   2663\n",
      "high                  0.254046   2657\n",
      "\n",
      "[age_group]\n",
      "           churn_rate  count\n",
      "age_group                   \n",
      "adult        0.268035   1705\n",
      "senior       0.262307   2844\n",
      "middle       0.253474   1799\n",
      "young        0.249395   1652\n",
      "\n",
      "▶ 카테고리 간 이탈률 차이가 크지 않으면 → 범주형이 이탈 예측에 별 도움 안 됨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiyon\\AppData\\Local\\Temp\\ipykernel_24192\\4263521319.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  churn_by_cat = df_fe.groupby(col)[\"is_churned\"].agg([\"mean\", \"count\"])\n",
      "C:\\Users\\jiyon\\AppData\\Local\\Temp\\ipykernel_24192\\4263521319.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  churn_by_cat = df_fe.groupby(col)[\"is_churned\"].agg([\"mean\", \"count\"])\n"
     ]
    }
   ],
   "source": [
    "# 6-2. 범주형 피처: 카테고리별 이탈률 차이\n",
    "\n",
    "print(\"\\n=== 범주형 피처별 이탈률 ===\\n\")\n",
    "\n",
    "cat_features = RAW_CAT_COLS + [\"listening_time_bin\", \"age_group\"]\n",
    "\n",
    "for col in cat_features:\n",
    "    if col not in df_fe.columns:\n",
    "        continue\n",
    "    \n",
    "    churn_by_cat = df_fe.groupby(col)[\"is_churned\"].agg([\"mean\", \"count\"])\n",
    "    churn_by_cat.columns = [\"churn_rate\", \"count\"]\n",
    "    churn_by_cat = churn_by_cat.sort_values(\"churn_rate\", ascending=False)\n",
    "    \n",
    "    print(f\"\\n[{col}]\")\n",
    "    print(churn_by_cat.to_string())\n",
    "    \n",
    "print(\"\\n▶ 카테고리 간 이탈률 차이가 크지 않으면 → 범주형이 이탈 예측에 별 도움 안 됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7542b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 피처 vs is_churned 상관계수 (Point-Biserial) ===\n",
      "\n",
      "              feature  correlation  p_value\n",
      "        skip_rate_cap     0.019652 0.078815\n",
      "            skip_rate     0.016598 0.137689\n",
      "    offline_listening     0.012754 0.254029\n",
      " songs_played_per_day     0.009776 0.381956\n",
      "       skip_intensity     0.009734 0.384001\n",
      "       listening_time    -0.007217 0.518678\n",
      "     songs_per_minute     0.005664 0.612463\n",
      "                  age     0.004666 0.676458\n",
      "ads_listened_per_week    -0.002279 0.838474\n",
      "     engagement_score     0.001781 0.873438\n",
      "\n",
      "▶ |correlation|이 0.1 미만이면 → 이탈과 거의 선형 관계 없음\n",
      "▶ 모든 피처의 상관계수가 약하면 → 단순 선형 모델로는 예측 한계\n",
      "▶ RF도 비선형 조합을 찾지 못하면 → F1이 낮게 나올 수밖에 없음\n"
     ]
    }
   ],
   "source": [
    "# 6-3. 상관계수: 피처 vs is_churned (Point-Biserial Correlation)\n",
    "\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "print(\"\\n=== 피처 vs is_churned 상관계수 (Point-Biserial) ===\\n\")\n",
    "\n",
    "corr_results = []\n",
    "\n",
    "for col in numeric_features:\n",
    "    if col not in df_fe.columns:\n",
    "        continue\n",
    "    \n",
    "    # Point-Biserial Correlation (연속형 vs 이진)\n",
    "    vals = df_fe[col].dropna()\n",
    "    target = df_fe.loc[vals.index, \"is_churned\"]\n",
    "    \n",
    "    corr, p_val = pointbiserialr(target, vals)\n",
    "    \n",
    "    corr_results.append({\n",
    "        \"feature\": col,\n",
    "        \"correlation\": corr,\n",
    "        \"p_value\": p_val,\n",
    "    })\n",
    "\n",
    "corr_df = pd.DataFrame(corr_results).sort_values(\"correlation\", key=abs, ascending=False)\n",
    "print(corr_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n▶ |correlation|이 0.1 미만이면 → 이탈과 거의 선형 관계 없음\")\n",
    "print(\"▶ 모든 피처의 상관계수가 약하면 → 단순 선형 모델로는 예측 한계\")\n",
    "print(\"▶ RF도 비선형 조합을 찾지 못하면 → F1이 낮게 나올 수밖에 없음\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85aac802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RF Feature Importance (X_num_only) ===\n",
      "\n",
      "              feature  importance\n",
      "     songs_per_minute    0.143454\n",
      "     engagement_score    0.141516\n",
      "       skip_intensity    0.134431\n",
      "       listening_time    0.129051\n",
      "                  age    0.124598\n",
      " songs_played_per_day    0.104091\n",
      "            skip_rate    0.085738\n",
      "        skip_rate_cap    0.083754\n",
      "ads_listened_per_week    0.042155\n",
      "    offline_listening    0.011214\n",
      "\n",
      "=== Permutation Importance (F1 기준, X_num_only) ===\n",
      "\n",
      "              feature  perm_importance_mean  perm_importance_std\n",
      "     songs_per_minute              0.076790             0.006422\n",
      " songs_played_per_day              0.073286             0.008196\n",
      "       listening_time              0.069356             0.008617\n",
      "     engagement_score              0.068503             0.007189\n",
      "       skip_intensity              0.066470             0.006152\n",
      "            skip_rate              0.066110             0.007591\n",
      "        skip_rate_cap              0.061881             0.009809\n",
      "ads_listened_per_week              0.007372             0.005904\n",
      "    offline_listening              0.006733             0.006249\n",
      "                  age             -0.000517             0.011445\n",
      "\n",
      "▶ Feature Importance가 모두 비슷하면 → 단일 피처로 강력한 예측 불가\n",
      "▶ Permutation Importance가 낮으면 → 실제 성능에 기여 적음\n",
      "▶ 두 지표가 모두 낮으면 → 데이터 자체의 예측 신호가 약함\n"
     ]
    }
   ],
   "source": [
    "# 6-4. RF Feature Importance + Permutation Importance 통합 확인\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# 기본 RF 모델로 학습 (X_num_only 기준)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_num_only, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "rf_for_imp = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_for_imp.fit(X_train, y_train)\n",
    "\n",
    "# (1) Feature Importance\n",
    "feat_imp = rf_for_imp.feature_importances_\n",
    "feat_names = X_num_only.columns\n",
    "\n",
    "imp_df = pd.DataFrame({\"feature\": feat_names, \"importance\": feat_imp})\n",
    "imp_df = imp_df.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n=== RF Feature Importance (X_num_only) ===\\n\")\n",
    "print(imp_df.to_string(index=False))\n",
    "\n",
    "# (2) Permutation Importance\n",
    "perm_imp = permutation_importance(\n",
    "    rf_for_imp, X_valid, y_valid, n_repeats=10, random_state=42, scoring=\"f1\"\n",
    ")\n",
    "\n",
    "perm_imp_df = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"perm_importance_mean\": perm_imp.importances_mean,\n",
    "    \"perm_importance_std\": perm_imp.importances_std,\n",
    "})\n",
    "perm_imp_df = perm_imp_df.sort_values(\"perm_importance_mean\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Permutation Importance (F1 기준, X_num_only) ===\\n\")\n",
    "print(perm_imp_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n▶ Feature Importance가 모두 비슷하면 → 단일 피처로 강력한 예측 불가\")\n",
    "print(\"▶ Permutation Importance가 낮으면 → 실제 성능에 기여 적음\")\n",
    "print(\"▶ 두 지표가 모두 낮으면 → 데이터 자체의 예측 신호가 약함\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba536b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 최종 진단 요약\n",
    "\n",
    "위 섹션 6의 분석 결과를 종합하면, **\"왜 F1이 0.41대에서 막히는가?\"**의 근본 원인을 찾을 수 있습니다.\n",
    "\n",
    "### 예상되는 원인들 (분석 후 확인)\n",
    "\n",
    "1. **피처 vs 이탈 간 상관이 약함**  \n",
    "   - 모든 수치형 피처의 상관계수가 |0.1| 미만이면 → 단순 선형으로는 예측 불가  \n",
    "   - RF도 비선형 조합을 못 찾으면 → 성능 한계\n",
    "\n",
    "2. **범주형 피처의 이탈률 차이가 작음**  \n",
    "   - 예: Free vs Premium 이탈률 차이가 5%p 이내면 → 범주형 추가해도 성능 향상 미미\n",
    "\n",
    "3. **Feature Importance가 모두 고르게 분산**  \n",
    "   - 특정 피처가 압도적으로 중요하지 않고, 10개가 골고루 10% 내외씩 → **단일 강력 예측 변수 없음**\n",
    "\n",
    "4. **데이터 구조 자체의 한계**  \n",
    "   - 유저당 1행 스냅샷 → 시계열 정보 없음  \n",
    "   - 이탈 직전의 급격한 행동 변화를 포착 불가  \n",
    "   - 결과적으로 **\"이탈 예측 신호\"가 약한 데이터 구조**\n",
    "\n",
    "### 대응 방향\n",
    "\n",
    "- **현재 F1 0.41 ~ 0.42**를 \"이 데이터에서의 현실적 상한\"으로 보고,  \n",
    "  → 발표 때는 **\"데이터 한계 + 추가 데이터 필요성\"**을 중심으로 스토리 구성  \n",
    "- 추가 성능 향상보다는 **\"왜 한계인가에 대한 근거 기반 설명\"**이 더 설득력 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a8def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
