{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef05b95",
   "metadata": {},
   "source": [
    "# SMOTE + XGBoost íŠœë‹ + ì•™ìƒë¸” ìµœì¢… ì„±ëŠ¥ í–¥ìƒ ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì˜ ëª©í‘œ:\n",
    "- **SMOTE ì˜¤ë²„ìƒ˜í”Œë§**ìœ¼ë¡œ ì´íƒˆ í´ë˜ìŠ¤ ê· í˜• ë§ì¶”ê¸°\n",
    "- **XGBoost GridSearchCV**ë¡œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì°¾ê¸°\n",
    "- **RF + XGBoost + HGB ì†Œí”„íŠ¸ ë³´íŒ… ì•™ìƒë¸”**\n",
    "- **ìµœì¢… F1 0.45+, AUC 0.56+ ëª©í‘œ**\n",
    "\n",
    "ê¸°ì¡´ `feature_selection.ipynb`ì—ì„œ í™•ì¸í•œ ë¬¸ì œ:\n",
    "- ë°ì´í„° ìì²´ì˜ ì´íƒˆ ì‹ í˜¸ê°€ ì•½í•¨ (ìƒê´€ê³„ìˆ˜ < 0.02)\n",
    "- ê¸°ë³¸ RF: F1 0.412, AUC 0.528\n",
    "- ë²”ì£¼í˜• ì¶”ê°€/íŠœë‹í•´ë„ ê°œì„  ì—†ìŒ\n",
    "\n",
    "â†’ **ë§ˆì§€ë§‰ ì‹œë„: SMOTE + XGBoost + ì•™ìƒë¸”ë¡œ í•œê³„ ëŒíŒŒ**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a34909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8000, 10)\n",
      "y ë¶„í¬:\n",
      "is_churned\n",
      "0    5929\n",
      "1    2071\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. ë°ì´í„° ë¡œë“œ ë° FE ìƒì„± (feature_selection.ipynb ë¡œì§ ì¬ì‚¬ìš©)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "DATA_PATH = \"../data/raw_data.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "BASE_NUM_COLS = [\n",
    "    \"age\",\n",
    "    \"listening_time\",\n",
    "    \"songs_played_per_day\",\n",
    "    \"skip_rate\",\n",
    "    \"ads_listened_per_week\",\n",
    "    \"offline_listening\",\n",
    "]\n",
    "\n",
    "NUM_FE_COLS = [\n",
    "    \"engagement_score\",\n",
    "    \"songs_per_minute\",\n",
    "    \"skip_intensity\",\n",
    "    \"skip_rate_cap\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_fe_dataframe(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬ + í•µì‹¬ FE 4ê°œ ìƒì„±\"\"\"\n",
    "    df_tmp = df_in.copy()\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ median ì²˜ë¦¬\n",
    "    for c in BASE_NUM_COLS:\n",
    "        if c in df_tmp.columns and df_tmp[c].isnull().any():\n",
    "            df_tmp[c] = df_tmp[c].fillna(df_tmp[c].median())\n",
    "\n",
    "    # FE ìƒì„±\n",
    "    if {\"listening_time\", \"songs_played_per_day\"}.issubset(df_tmp.columns):\n",
    "        df_tmp[\"engagement_score\"] = (\n",
    "            df_tmp[\"listening_time\"] * df_tmp[\"songs_played_per_day\"]\n",
    "        )\n",
    "\n",
    "    lt_safe = df_tmp[\"listening_time\"].replace(0, np.nan)\n",
    "    df_tmp[\"songs_per_minute\"] = (\n",
    "        df_tmp[\"songs_played_per_day\"] / lt_safe\n",
    "    ).fillna(0.0)\n",
    "\n",
    "    if \"skip_rate\" in df_tmp.columns:\n",
    "        df_tmp[\"skip_rate_cap\"] = df_tmp[\"skip_rate\"].clip(lower=0, upper=1.5)\n",
    "        df_tmp[\"skip_intensity\"] = df_tmp[\"skip_rate\"] * df_tmp[\"songs_played_per_day\"]\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "df_fe = make_fe_dataframe(df)\n",
    "\n",
    "# X, y ë¶„ë¦¬ (ìˆ˜ì¹˜í˜• + í•µì‹¬ FEë§Œ ì‚¬ìš©)\n",
    "ALL_FEAT_COLS = BASE_NUM_COLS + NUM_FE_COLS\n",
    "X = df_fe[ALL_FEAT_COLS]\n",
    "y = df_fe[\"is_churned\"]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y ë¶„í¬:\\n{y.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca794e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë°ì´í„°:\n",
      "X_train shape: (6400, 10)\n",
      "y_train ë¶„í¬:\n",
      "is_churned\n",
      "0    4743\n",
      "1    1657\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SMOTE ì ìš© í›„:\n",
      "X_train_smote shape: (9486, 10)\n",
      "y_train_smote ë¶„í¬:\n",
      "is_churned\n",
      "0    4743\n",
      "1    4743\n",
      "Name: count, dtype: int64\n",
      "\n",
      "â–¶ SMOTEëŠ” trainì—ë§Œ ì ìš©, testëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€ (leakage ë°©ì§€)\n"
     ]
    }
   ],
   "source": [
    "# 2. Train/Test Split + SMOTE ì˜¤ë²„ìƒ˜í”Œë§ (trainì—ë§Œ ì ìš©)\n",
    "\n",
    "# Train/Test ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"ì›ë³¸ ë°ì´í„°:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train ë¶„í¬:\\n{pd.Series(y_train).value_counts()}\")\n",
    "\n",
    "# SMOTE ì ìš© (trainì—ë§Œ!)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nSMOTE ì ìš© í›„:\")\n",
    "print(f\"X_train_smote shape: {X_train_smote.shape}\")\n",
    "print(f\"y_train_smote ë¶„í¬:\\n{pd.Series(y_train_smote).value_counts()}\")\n",
    "\n",
    "print(\"\\nâ–¶ SMOTEëŠ” trainì—ë§Œ ì ìš©, testëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€ (leakage ë°©ì§€)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f1d6c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline RF (no SMOTE) ===\n",
      "F1 = 0.4127 @ th=0.10, AUC = 0.5289\n"
     ]
    }
   ],
   "source": [
    "# 3. Baseline: RF (SMOTE ì—†ì´)\n",
    "\n",
    "def evaluate_with_threshold_tuning(y_true, y_proba, thresholds=None):\n",
    "    \"\"\"threshold íŠœë‹ìœ¼ë¡œ best F1 ê³„ì‚°\"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.round(np.arange(0.05, 0.36, 0.01), 2)\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    best_th = 0.5\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_proba >= th).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred_th)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = th\n",
    "    \n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    return best_f1, best_th, auc\n",
    "\n",
    "\n",
    "# Baseline RF (SMOTE ì—†ì´, ì›ë³¸ train ì‚¬ìš©)\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "y_proba_baseline = rf_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "f1_baseline, th_baseline, auc_baseline = evaluate_with_threshold_tuning(y_test, y_proba_baseline)\n",
    "\n",
    "print(\"=== Baseline RF (no SMOTE) ===\")\n",
    "print(f\"F1 = {f1_baseline:.4f} @ th={th_baseline:.2f}, AUC = {auc_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c11fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RF + SMOTE ===\n",
      "F1 = 0.4110 @ th=0.08, AUC = 0.5115\n",
      "vs Baseline: Î”F1 = -0.0017, Î”AUC = -0.0174\n"
     ]
    }
   ],
   "source": [
    "# 4. RF + SMOTE\n",
    "\n",
    "rf_smote = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_smote.fit(X_train_smote, y_train_smote)\n",
    "y_proba_rf_smote = rf_smote.predict_proba(X_test)[:, 1]\n",
    "\n",
    "f1_rf_smote, th_rf_smote, auc_rf_smote = evaluate_with_threshold_tuning(y_test, y_proba_rf_smote)\n",
    "\n",
    "print(\"=== RF + SMOTE ===\")\n",
    "print(f\"F1 = {f1_rf_smote:.4f} @ th={th_rf_smote:.2f}, AUC = {auc_rf_smote:.4f}\")\n",
    "print(f\"vs Baseline: Î”F1 = {f1_rf_smote - f1_baseline:+.4f}, Î”AUC = {auc_rf_smote - auc_baseline:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ae228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost GridSearchCV fitting... (ì‹œê°„ ì†Œìš” ì˜ˆìƒ: 5~10ë¶„)\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "\n",
      "Best params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'scale_pos_weight': 4}\n",
      "Best CV F1 (train): 0.6645\n",
      "\n",
      "=== XGBoost + SMOTE (tuned) ===\n",
      "F1 = 0.4107 @ th=0.05, AUC = 0.4906\n",
      "vs Baseline: Î”F1 = -0.0020, Î”AUC = -0.0383\n"
     ]
    }
   ],
   "source": [
    "# 5. XGBoost GridSearchCV (SMOTE ë°ì´í„° ê¸°ë°˜)\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_base = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'scale_pos_weight': [2, 3, 4],  # ì´íƒˆ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid_xgb,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"XGBoost GridSearchCV fitting... (ì‹œê°„ ì†Œìš” ì˜ˆìƒ: 5~10ë¶„)\")\n",
    "grid_xgb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(f\"\\nBest params: {grid_xgb.best_params_}\")\n",
    "print(f\"Best CV F1 (train): {grid_xgb.best_score_:.4f}\")\n",
    "\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "y_proba_xgb = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "f1_xgb, th_xgb, auc_xgb = evaluate_with_threshold_tuning(y_test, y_proba_xgb)\n",
    "\n",
    "print(f\"\\n=== XGBoost + SMOTE (tuned) ===\")\n",
    "print(f\"F1 = {f1_xgb:.4f} @ th={th_xgb:.2f}, AUC = {auc_xgb:.4f}\")\n",
    "print(f\"vs Baseline: Î”F1 = {f1_xgb - f1_baseline:+.4f}, Î”AUC = {auc_xgb - auc_baseline:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3630cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble fitting...\n",
      "\n",
      "=== Ensemble (RF + XGBoost + HGB) ===\n",
      "F1 = 0.4118 @ th=0.14, AUC = 0.4991\n",
      "vs Baseline: Î”F1 = -0.0009, Î”AUC = -0.0298\n"
     ]
    }
   ],
   "source": [
    "# 6. ì†Œí”„íŠ¸ ë³´íŒ… ì•™ìƒë¸” (RF + XGBoost + HGB)\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_smote),\n",
    "        ('xgb', best_xgb),\n",
    "        ('hgb', hgb_clf),\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"Ensemble fitting...\")\n",
    "ensemble.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_proba_ens = ensemble.predict_proba(X_test)[:, 1]\n",
    "\n",
    "f1_ens, th_ens, auc_ens = evaluate_with_threshold_tuning(y_test, y_proba_ens)\n",
    "\n",
    "print(\"\\n=== Ensemble (RF + XGBoost + HGB) ===\")\n",
    "print(f\"F1 = {f1_ens:.4f} @ th={th_ens:.2f}, AUC = {auc_ens:.4f}\")\n",
    "print(f\"vs Baseline: Î”F1 = {f1_ens - f1_baseline:+.4f}, Î”AUC = {auc_ens - auc_baseline:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b0d210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ìµœì¢… ê²°ê³¼ ë¹„êµ\n",
      "================================================================================\n",
      "                  Model       F1  Threshold      AUC\n",
      " Baseline RF (no SMOTE) 0.412714       0.10 0.528902\n",
      "             RF + SMOTE 0.410973       0.08 0.511467\n",
      "XGBoost + SMOTE (tuned) 0.410741       0.05 0.490568\n",
      "  Ensemble (RF+XGB+HGB) 0.411824       0.14 0.499086\n",
      "\n",
      "================================================================================\n",
      "âœ… ìµœê³  F1 ëª¨ë¸: Baseline RF (no SMOTE)\n",
      "   F1 = 0.4127, AUC = 0.5289\n",
      "\n",
      "âœ… ìµœê³  AUC ëª¨ë¸: Baseline RF (no SMOTE)\n",
      "   F1 = 0.4127, AUC = 0.5289\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 7. ìµœì¢… ê²°ê³¼ ë¹„êµ ë° ìš”ì•½\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline RF (no SMOTE)\", \"F1\": f1_baseline, \"Threshold\": th_baseline, \"AUC\": auc_baseline},\n",
    "    {\"Model\": \"RF + SMOTE\", \"F1\": f1_rf_smote, \"Threshold\": th_rf_smote, \"AUC\": auc_rf_smote},\n",
    "    {\"Model\": \"XGBoost + SMOTE (tuned)\", \"F1\": f1_xgb, \"Threshold\": th_xgb, \"AUC\": auc_xgb},\n",
    "    {\"Model\": \"Ensemble (RF+XGB+HGB)\", \"F1\": f1_ens, \"Threshold\": th_ens, \"AUC\": auc_ens},\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ìµœì¢… ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\" * 80)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°\n",
    "best_f1_idx = results['F1'].idxmax()\n",
    "best_auc_idx = results['AUC'].idxmax()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… ìµœê³  F1 ëª¨ë¸: {results.loc[best_f1_idx, 'Model']}\")\n",
    "print(f\"   F1 = {results.loc[best_f1_idx, 'F1']:.4f}, AUC = {results.loc[best_f1_idx, 'AUC']:.4f}\")\n",
    "print()\n",
    "print(f\"âœ… ìµœê³  AUC ëª¨ë¸: {results.loc[best_auc_idx, 'Model']}\")\n",
    "print(f\"   F1 = {results.loc[best_auc_idx, 'F1']:.4f}, AUC = {results.loc[best_auc_idx, 'AUC']:.4f}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab998ed1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„\n",
    "\n",
    "ìœ„ ê²°ê³¼ì—ì„œ SMOTEê°€ ì—­íš¨ê³¼ë¥¼ ëƒˆì§€ë§Œ, **ì„¤ì •ì„ ì¡°ì •í•˜ë©´ ê°œì„  ê°€ëŠ¥ì„±**ì´ ìˆìŒ:\n",
    "\n",
    "### ë³€ê²½ ì‚¬í•­\n",
    "1. **test_size = 0.15** (train ë” ë§ì´ í™•ë³´)\n",
    "2. **SMOTE sampling_strategy = 0.5** (ì™„ì „ ê· í˜• ëŒ€ì‹  ì ˆë°˜ë§Œ ì˜¤ë²„ìƒ˜í”Œë§)\n",
    "3. **XGBoost scale_pos_weight = [5, 6, 7, 8]** (ì´íƒˆ í´ë˜ìŠ¤ì— ë” ê°•í•œ ê°€ì¤‘ì¹˜)\n",
    "4. **threshold ë²”ìœ„ = 0.01~0.15, step=0.005** (ë” ì„¸ë°€í•œ íƒìƒ‰)\n",
    "\n",
    "ëª©í‘œ: F1 0.43+, AUC 0.53+ ë‹¬ì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4e6e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ìµœì í™” ì„¤ì • v2 ===\n",
      "X_train_v2 shape: (6800, 10)\n",
      "X_test_v2 shape: (1200, 10)\n",
      "\n",
      "SMOTE ì ìš© í›„ (sampling_strategy=0.5):\n",
      "y_train_smote_v2 ë¶„í¬:\n",
      "is_churned\n",
      "0    5040\n",
      "1    2520\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 8-1. ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„: Train/Test Split + SMOTE\n",
    "\n",
    "# Train/Test ë¶„ë¦¬ (test_size=0.15ë¡œ ì¤„ì„)\n",
    "X_train_v2, X_test_v2, y_train_v2, y_test_v2 = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=== ìµœì í™” ì„¤ì • v2 ===\")\n",
    "print(f\"X_train_v2 shape: {X_train_v2.shape}\")\n",
    "print(f\"X_test_v2 shape: {X_test_v2.shape}\")\n",
    "\n",
    "# SMOTE ì ìš© (sampling_strategy=0.5 â†’ 50%ë§Œ ì˜¤ë²„ìƒ˜í”Œë§)\n",
    "smote_v2 = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "X_train_smote_v2, y_train_smote_v2 = smote_v2.fit_resample(X_train_v2, y_train_v2)\n",
    "\n",
    "print(f\"\\nSMOTE ì ìš© í›„ (sampling_strategy=0.5):\")\n",
    "print(f\"y_train_smote_v2 ë¶„í¬:\\n{pd.Series(y_train_smote_v2).value_counts()}\")\n",
    "\n",
    "\n",
    "# threshold í•¨ìˆ˜ ì¬ì •ì˜ (ë” ì„¸ë°€í•œ ë²”ìœ„)\n",
    "def evaluate_with_fine_threshold(y_true, y_proba):\n",
    "    \"\"\"threshold 0.01~0.15 êµ¬ê°„, 0.005 ê°„ê²©ìœ¼ë¡œ ì„¸ë°€í•˜ê²Œ íƒìƒ‰\"\"\"\n",
    "    thresholds = np.round(np.arange(0.01, 0.16, 0.005), 3)\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    best_th = 0.5\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_proba >= th).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred_th)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = th\n",
    "    \n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    return best_f1, best_th, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c00e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline RF v2 (test_size=0.15, no SMOTE) ===\n",
      "F1 = 0.4146 @ th=0.105, AUC = 0.5307\n"
     ]
    }
   ],
   "source": [
    "# 8-2. Baseline v2 (ìµœì í™” ì„¤ì •, SMOTE ì—†ì´)\n",
    "\n",
    "rf_baseline_v2 = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_baseline_v2.fit(X_train_v2, y_train_v2)\n",
    "y_proba_baseline_v2 = rf_baseline_v2.predict_proba(X_test_v2)[:, 1]\n",
    "\n",
    "f1_baseline_v2, th_baseline_v2, auc_baseline_v2 = evaluate_with_fine_threshold(y_test_v2, y_proba_baseline_v2)\n",
    "\n",
    "print(\"=== Baseline RF v2 (test_size=0.15, no SMOTE) ===\")\n",
    "print(f\"F1 = {f1_baseline_v2:.4f} @ th={th_baseline_v2:.3f}, AUC = {auc_baseline_v2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a718edd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RF + SMOTE v2 (sampling_strategy=0.5) ===\n",
      "F1 = 0.4136 @ th=0.090, AUC = 0.5223\n",
      "vs Baseline v2: Î”F1 = -0.0010, Î”AUC = -0.0084\n"
     ]
    }
   ],
   "source": [
    "# 8-3. RF + SMOTE v2 (sampling_strategy=0.5)\n",
    "\n",
    "rf_smote_v2 = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_smote_v2.fit(X_train_smote_v2, y_train_smote_v2)\n",
    "y_proba_rf_smote_v2 = rf_smote_v2.predict_proba(X_test_v2)[:, 1]\n",
    "\n",
    "f1_rf_smote_v2, th_rf_smote_v2, auc_rf_smote_v2 = evaluate_with_fine_threshold(y_test_v2, y_proba_rf_smote_v2)\n",
    "\n",
    "print(\"=== RF + SMOTE v2 (sampling_strategy=0.5) ===\")\n",
    "print(f\"F1 = {f1_rf_smote_v2:.4f} @ th={th_rf_smote_v2:.3f}, AUC = {auc_rf_smote_v2:.4f}\")\n",
    "print(f\"vs Baseline v2: Î”F1 = {f1_rf_smote_v2 - f1_baseline_v2:+.4f}, Î”AUC = {auc_rf_smote_v2 - auc_baseline_v2:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2172711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost v2 GridSearchCV fitting...\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best params v2: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'scale_pos_weight': 8}\n",
      "Best CV F1 (train): 0.5002\n",
      "\n",
      "=== XGBoost v2 + SMOTE (scale_pos_weight í™•ì¥) ===\n",
      "F1 = 0.4119 @ th=0.035, AUC = 0.4937\n",
      "vs Baseline v2: Î”F1 = -0.0027, Î”AUC = -0.0370\n"
     ]
    }
   ],
   "source": [
    "# 8-4. XGBoost v2 (scale_pos_weight í™•ì¥ + ë¹ ë¥¸ íƒìƒ‰)\n",
    "\n",
    "xgb_base_v2 = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ë²”ìœ„ ì¡°ì • (scale_pos_weight í™•ì¥, íƒìƒ‰ ë²”ìœ„ ì¶•ì†Œ)\n",
    "param_grid_xgb_v2 = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [5, 7],\n",
    "    'learning_rate': [0.03, 0.05],\n",
    "    'scale_pos_weight': [5, 6, 7, 8],  # ë” ê°•í•œ ê°€ì¤‘ì¹˜\n",
    "}\n",
    "\n",
    "grid_xgb_v2 = GridSearchCV(\n",
    "    estimator=xgb_base_v2,\n",
    "    param_grid=param_grid_xgb_v2,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"XGBoost v2 GridSearchCV fitting...\")\n",
    "grid_xgb_v2.fit(X_train_smote_v2, y_train_smote_v2)\n",
    "\n",
    "print(f\"\\nBest params v2: {grid_xgb_v2.best_params_}\")\n",
    "print(f\"Best CV F1 (train): {grid_xgb_v2.best_score_:.4f}\")\n",
    "\n",
    "best_xgb_v2 = grid_xgb_v2.best_estimator_\n",
    "y_proba_xgb_v2 = best_xgb_v2.predict_proba(X_test_v2)[:, 1]\n",
    "\n",
    "f1_xgb_v2, th_xgb_v2, auc_xgb_v2 = evaluate_with_fine_threshold(y_test_v2, y_proba_xgb_v2)\n",
    "\n",
    "print(f\"\\n=== XGBoost v2 + SMOTE (scale_pos_weight í™•ì¥) ===\")\n",
    "print(f\"F1 = {f1_xgb_v2:.4f} @ th={th_xgb_v2:.3f}, AUC = {auc_xgb_v2:.4f}\")\n",
    "print(f\"vs Baseline v2: Î”F1 = {f1_xgb_v2 - f1_baseline_v2:+.4f}, Î”AUC = {auc_xgb_v2 - auc_baseline_v2:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f4ab9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble v2 fitting...\n",
      "\n",
      "=== Ensemble v2 (RF + XGBoost + HGB) ===\n",
      "F1 = 0.4128 @ th=0.130, AUC = 0.5086\n",
      "vs Baseline v2: Î”F1 = -0.0018, Î”AUC = -0.0222\n"
     ]
    }
   ],
   "source": [
    "# 8-5. ì•™ìƒë¸” v2\n",
    "\n",
    "ensemble_v2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_smote_v2),\n",
    "        ('xgb', best_xgb_v2),\n",
    "        ('hgb', HistGradientBoostingClassifier(random_state=42)),\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"Ensemble v2 fitting...\")\n",
    "ensemble_v2.fit(X_train_smote_v2, y_train_smote_v2)\n",
    "\n",
    "y_proba_ens_v2 = ensemble_v2.predict_proba(X_test_v2)[:, 1]\n",
    "\n",
    "f1_ens_v2, th_ens_v2, auc_ens_v2 = evaluate_with_fine_threshold(y_test_v2, y_proba_ens_v2)\n",
    "\n",
    "print(\"\\n=== Ensemble v2 (RF + XGBoost + HGB) ===\")\n",
    "print(f\"F1 = {f1_ens_v2:.4f} @ th={th_ens_v2:.3f}, AUC = {auc_ens_v2:.4f}\")\n",
    "print(f\"vs Baseline v2: Î”F1 = {f1_ens_v2 - f1_baseline_v2:+.4f}, Î”AUC = {auc_ens_v2 - auc_baseline_v2:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd6020e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ìµœì í™” ì„¤ì • v2 ê²°ê³¼ ë¹„êµ\n",
      "================================================================================\n",
      "         Model       F1  Threshold      AUC\n",
      "Baseline RF v2 0.414634      0.105 0.530724\n",
      " RF + SMOTE v2 0.413609      0.090 0.522347\n",
      "    XGBoost v2 0.411921      0.035 0.493721\n",
      "   Ensemble v2 0.412826      0.130 0.508563\n",
      "\n",
      "================================================================================\n",
      "âœ… ìµœê³  F1 ëª¨ë¸ (v2): Baseline RF v2\n",
      "   F1 = 0.4146, AUC = 0.5307\n",
      "\n",
      "âœ… ìµœê³  AUC ëª¨ë¸ (v2): Baseline RF v2\n",
      "   F1 = 0.4146, AUC = 0.5307\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "v1 (ì›ë˜ ì„¤ì •) vs v2 (ìµœì í™” ì„¤ì •) ë¹„êµ\n",
      "================================================================================\n",
      "v1 Baseline: F1 = 0.4127, AUC = 0.5289\n",
      "v2 Baseline: F1 = 0.4146, AUC = 0.5307\n",
      "ê°œì„ : Î”F1 = +0.0019, Î”AUC = +0.0018\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 8-6. ìµœì¢… ë¹„êµ (v1 vs v2)\n",
    "\n",
    "results_v2 = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline RF v2\", \"F1\": f1_baseline_v2, \"Threshold\": th_baseline_v2, \"AUC\": auc_baseline_v2},\n",
    "    {\"Model\": \"RF + SMOTE v2\", \"F1\": f1_rf_smote_v2, \"Threshold\": th_rf_smote_v2, \"AUC\": auc_rf_smote_v2},\n",
    "    {\"Model\": \"XGBoost v2\", \"F1\": f1_xgb_v2, \"Threshold\": th_xgb_v2, \"AUC\": auc_xgb_v2},\n",
    "    {\"Model\": \"Ensemble v2\", \"F1\": f1_ens_v2, \"Threshold\": th_ens_v2, \"AUC\": auc_ens_v2},\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ìµœì í™” ì„¤ì • v2 ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\" * 80)\n",
    "print(results_v2.to_string(index=False))\n",
    "\n",
    "best_f1_idx_v2 = results_v2['F1'].idxmax()\n",
    "best_auc_idx_v2 = results_v2['AUC'].idxmax()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… ìµœê³  F1 ëª¨ë¸ (v2): {results_v2.loc[best_f1_idx_v2, 'Model']}\")\n",
    "print(f\"   F1 = {results_v2.loc[best_f1_idx_v2, 'F1']:.4f}, AUC = {results_v2.loc[best_f1_idx_v2, 'AUC']:.4f}\")\n",
    "print()\n",
    "print(f\"âœ… ìµœê³  AUC ëª¨ë¸ (v2): {results_v2.loc[best_auc_idx_v2, 'Model']}\")\n",
    "print(f\"   F1 = {results_v2.loc[best_auc_idx_v2, 'F1']:.4f}, AUC = {results_v2.loc[best_auc_idx_v2, 'AUC']:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"v1 (ì›ë˜ ì„¤ì •) vs v2 (ìµœì í™” ì„¤ì •) ë¹„êµ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"v1 Baseline: F1 = {f1_baseline:.4f}, AUC = {auc_baseline:.4f}\")\n",
    "print(f\"v2 Baseline: F1 = {f1_baseline_v2:.4f}, AUC = {auc_baseline_v2:.4f}\")\n",
    "print(f\"ê°œì„ : Î”F1 = {f1_baseline_v2 - f1_baseline:+.4f}, Î”AUC = {auc_baseline_v2 - auc_baseline:+.4f}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de07ac7",
   "metadata": {},
   "source": [
    "# Spotify ì´íƒˆ ì˜ˆì¸¡ í”„ë¡œì íŠ¸ - ìµœì¢… ì •ë¦¬ ë° ê°œì„  ë°©í–¥\n",
    "\n",
    "## 1. í”„ë¡œì íŠ¸ ëª©í‘œ ë° ì§„í–‰ ê³¼ì •\n",
    "\n",
    "### ì´ˆê¸° ëª©í‘œ\n",
    "- ìœ ì € í–‰ë™ ë°ì´í„° ê¸°ë°˜ ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•\n",
    "- ëª©í‘œ ì„±ëŠ¥: F1 0.6+, AUC 0.7+\n",
    "\n",
    "### ë°ì´í„° ê°œìš”\n",
    "- ì´ 8,000ëª… ìœ ì € (ìœ ì €ë‹¹ 1í–‰ ìŠ¤ëƒ…ìƒ·)\n",
    "- ìˆ˜ì¹˜í˜• í”¼ì²˜ 6ê°œ + ë²”ì£¼í˜• í”¼ì²˜ 4ê°œ\n",
    "- ì´íƒˆë¥ : ì•½ 25.9%\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ì‹œë„í•œ ì‘ì—… ë° ê²°ê³¼\n",
    "\n",
    "### 2.1 Feature Engineering (FE_validation.ipynb, FE_add.ipynb)\n",
    "âœ… **ì‹œë„í•œ FE**\n",
    "- ê¸°ë³¸ FE 4ê°œ: engagement_score, skip_rate_cap, ads_pressure, listening_time_bin\n",
    "- ì¶”ê°€ FE 2ê°œ: songs_per_minute, skip_intensity\n",
    "- ì„¸ê·¸ë¨¼íŠ¸ í”Œë˜ê·¸ 5ê°œ: heavy_user_flag, mobile_free_flag, ë“±\n",
    "- êµí˜¸ì‘ìš© 7ê°œ: engagement_x_skip, songs_per_min_x_ads_pressure, ë“±\n",
    "\n",
    "âŒ **ê²°ê³¼**\n",
    "- ëª¨ë“  FE ì¶”ê°€í•´ë„ F1 0.41ëŒ€ì—ì„œ ì •ì²´\n",
    "- ê¸°ë³¸ ìˆ˜ì¹˜í˜• 6ê°œ + í•µì‹¬ FE 4ê°œ = 10ê°œê°€ ìµœì  ì¡°í•©\n",
    "- ì¶”ê°€ FEëŠ” ì„±ëŠ¥ ì´ë“ ê±°ì˜ ì—†ìŒ (Î”F1 < Â±0.002)\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 ë²”ì£¼í˜• í”¼ì²˜ ì¶”ê°€ (feature_selection.ipynb)\n",
    "âœ… **ì‹œë„í•œ ê²ƒ**\n",
    "- gender, country, subscription_type, device_type ì›-í•« ì¸ì½”ë”©\n",
    "- ì´ 31ê°œ í”¼ì²˜ë¡œ í™•ì¥ (10ê°œ â†’ 31ê°œ)\n",
    "\n",
    "âŒ **ê²°ê³¼**\n",
    "- ìˆ˜ì¹˜í˜•ë§Œ: F1 0.4127, AUC 0.5289\n",
    "- ìˆ˜ì¹˜í˜•+ë²”ì£¼í˜•: F1 0.4113, AUC 0.5117\n",
    "- **ì˜¤íˆë ¤ ì—­íš¨ê³¼** (Î”F1 -0.0014, Î”AUC -0.0172)\n",
    "\n",
    "**ì›ì¸ ë¶„ì„:**\n",
    "- ë²”ì£¼í˜•ë³„ ì´íƒˆë¥  ì°¨ì´ê°€ ë¯¸ë¯¸ (ìµœëŒ€ 3%p)\n",
    "  - Free 24.9% vs Family 27.5%\n",
    "  - Mobile 26.9% vs Web 25.0%\n",
    "- ë²”ì£¼í˜• ì¶”ê°€í•´ë„ ì˜ˆì¸¡ ì‹ í˜¸ ì¦ê°€ ì—†ìŒ\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 ëª¨ë¸ íŠœë‹ ë° ì•™ìƒë¸” (feature_selection.ipynb)\n",
    "âœ… **ì‹œë„í•œ ê²ƒ**\n",
    "- K-Fold CV + threshold íŠœë‹ (0.05~0.35, step=0.01)\n",
    "- RF RandomizedSearchCV (25íšŒ íƒìƒ‰)\n",
    "- ì†Œí”„íŠ¸ ë³´íŒ… ì•™ìƒë¸” (RF + XGBoost + HGB)\n",
    "\n",
    "âŒ **ê²°ê³¼**\n",
    "- ê¸°ë³¸ RF: F1 0.4120, AUC 0.5280\n",
    "- íŠœë‹ RF: F1 0.4113, AUC 0.5071 (ì˜¤íˆë ¤ í•˜ë½)\n",
    "- ì•™ìƒë¸”: F1 0.4113, AUC 0.5169 (ì—­íš¨ê³¼)\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 SMOTE + XGBoost + ì•™ìƒë¸” (SMOTE_XGB_RF.ipynb)\n",
    "âœ… **ì‹œë„í•œ ê²ƒ (v1)**\n",
    "- SMOTE ì˜¤ë²„ìƒ˜í”Œë§ (1:1 ì™„ì „ ê· í˜•)\n",
    "- XGBoost GridSearchCV (81ê°œ ì¡°í•©, scale_pos_weight=2~4)\n",
    "- ì•™ìƒë¸” (RF + XGBoost + HGB)\n",
    "\n",
    "âŒ **ê²°ê³¼ (v1)**\n",
    "- Baseline RF: F1 0.4127, AUC 0.5289\n",
    "- RF+SMOTE: F1 0.4110, AUC 0.5115 (Î”AUC -0.017)\n",
    "- XGBoost: F1 0.4107, AUC 0.4906 (Î”AUC -0.038)\n",
    "- ì•™ìƒë¸”: F1 0.4118, AUC 0.4991 (Î”AUC -0.030)\n",
    "\n",
    "**ë¬¸ì œ:** SMOTE í•©ì„± ë°ì´í„°ì— ê³¼ì í•© (train F1 0.66 â†’ test F1 0.41)\n",
    "\n",
    "âœ… **ì¶”ê°€ ìµœì í™” (v2)**\n",
    "- test_size=0.15 (train ë” ë§ì´)\n",
    "- SMOTE sampling_strategy=0.5 (50%ë§Œ ì˜¤ë²„ìƒ˜í”Œë§)\n",
    "- XGBoost scale_pos_weight=5~8 (ë” ê°•í•œ ê°€ì¤‘ì¹˜)\n",
    "- threshold 0.01~0.15, step=0.005 (ë” ì„¸ë°€í•˜ê²Œ)\n",
    "\n",
    "âœ… **ê²°ê³¼ (v2) - ë¯¸ì„¸í•œ ê°œì„ **\n",
    "- Baseline RF v2: **F1 0.4146, AUC 0.5307**\n",
    "- vs v1: **Î”F1 +0.0019** (+0.46%), **Î”AUC +0.0018** (+0.34%)\n",
    "- ì—¬ì „íˆ SMOTE/XGBoost/ì•™ìƒë¸”ì€ ì—­íš¨ê³¼\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 ê·¼ë³¸ ì›ì¸ ë¶„ì„ (feature_selection.ipynb ì„¹ì…˜ 6)\n",
    "âœ… **ë°ì´í„° ìì²´ì˜ í•œê³„ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ ì…ì¦**\n",
    "\n",
    "#### (1) í”¼ì²˜ vs ì´íƒˆ ê°„ ìƒê´€ì´ ê·¹ë„ë¡œ ì•½í•¨\n",
    "- Point-Biserial Correlation (í”¼ì²˜ vs is_churned)\n",
    "  - ìµœê³ : skip_rate_cap = +0.0197\n",
    "  - ëŒ€ë¶€ë¶„: |0.01| ì´í•˜\n",
    "- **â†’ ëª¨ë“  í”¼ì²˜ê°€ ì´íƒˆê³¼ ì„ í˜• ê´€ê³„ ê±°ì˜ ì—†ìŒ**\n",
    "\n",
    "#### (2) ì´íƒˆ vs ë¹„ì´íƒˆ ê°„ í‰ê·  ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ\n",
    "- t-test ê²°ê³¼: **ëª¨ë“  í”¼ì²˜ì˜ p-value > 0.05**\n",
    "  - skip_rate_cap: p=0.084 (ê°€ì¥ ë‚®ìŒ, ê·¸ë˜ë„ ìœ ì˜ X)\n",
    "  - engagement_score: p=0.874\n",
    "- **â†’ ì´íƒˆ ê·¸ë£¹ê³¼ ë¹„ì´íƒˆ ê·¸ë£¹ì˜ í–‰ë™ì´ ê±°ì˜ ë™ì¼**\n",
    "\n",
    "#### (3) RF Feature Importanceê°€ ê³ ë¥´ê²Œ ë¶„ì‚°\n",
    "- 1ìœ„ songs_per_minute: 14.3%\n",
    "- 2ìœ„ engagement_score: 14.2%\n",
    "- ìƒìœ„ 7ê°œê°€ 8~14% ì‚¬ì´ì— ê³¨ê³ ë£¨ ë¶„ì‚°\n",
    "- **â†’ ë‹¨ì¼ ê°•ë ¥ ì˜ˆì¸¡ ë³€ìˆ˜ ì—†ìŒ**\n",
    "\n",
    "#### (4) Permutation Importanceë„ ë‚®ìŒ\n",
    "- ìµœê³ : songs_per_minute = 0.077\n",
    "- ëŒ€ë¶€ë¶„: 0.06~0.07\n",
    "- age: -0.0005 (ê±°ì˜ 0, ì˜¤íˆë ¤ ë°©í•´)\n",
    "- **â†’ í”¼ì²˜ë¥¼ ì„ì–´ë„ ì„±ëŠ¥ì´ ê±°ì˜ ì•ˆ ë–¨ì–´ì§ = ê¸°ì—¬ë„ ë‚®ìŒ**\n",
    "\n",
    "---\n",
    "\n",
    "## 3. ìµœì¢… ê²°ë¡ \n",
    "\n",
    "### 3.1 ì±„íƒ ëª¨ë¸ ë° ì„±ëŠ¥\n",
    "**ëª¨ë¸**: RandomForestClassifier (test_size=0.15, class_weight='balanced')\n",
    "- **F1 = 0.415**\n",
    "- **AUC = 0.531**\n",
    "- **threshold = 0.105**\n",
    "- **í”¼ì²˜**: ìˆ˜ì¹˜í˜• 6ê°œ + í•µì‹¬ FE 4ê°œ (ì´ 10ê°œ)\n",
    "\n",
    "### 3.2 í•œê³„ ë° ì›ì¸\n",
    "- **í˜„ì¬ F1 0.415ê°€ ì´ ë°ì´í„° êµ¬ì¡°ì—ì„œì˜ ì‹¤ì§ˆì  ìƒí•œ**\n",
    "- ëª¨ë“  ìµœì í™” ì‹œë„(FE/ë²”ì£¼í˜•/SMOTE/XGBoost/ì•™ìƒë¸”)ê°€ ì œí•œì  íš¨ê³¼\n",
    "- **ê·¼ë³¸ ì›ì¸**: ìœ ì €ë‹¹ 1í–‰ ìŠ¤ëƒ…ìƒ· êµ¬ì¡° â†’ ì´íƒˆ ì§ì „ í–‰ë™ ë³€í™” í¬ì°© ë¶ˆê°€\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ê°œì„  ë°©í–¥ ì œì•ˆ: ì»¬ëŸ¼ ì¶”ê°€\n",
    "\n",
    "### 4.1 ì‹œê³„ì—´ ì •ë³´ (í–‰ë™ ë³€í™” ì¶”ì )\n",
    "í˜„ì¬ ë°ì´í„°ëŠ” \"íŠ¹ì • ì‹œì ì˜ í‰ê· ê°’\"ë§Œ ìˆì–´ì„œ, **ì´íƒˆ ì§ì „ì˜ ê¸‰ê²©í•œ ë³€í™”**ë¥¼ í¬ì°© ëª» í•¨.\n",
    "\n",
    "**ì¶”ê°€ í•„ìš” ì»¬ëŸ¼:**\n",
    "1. `listening_time_trend_last_7days` (float)\n",
    "   - ìµœê·¼ 7ì¼ ì²­ì·¨ ì‹œê°„ ë³€í™”ìœ¨ (% change)\n",
    "   - ê¸‰ê²©íˆ ê°ì†Œí•˜ë©´ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: ìƒê´€ê³„ìˆ˜ 0.1~0.2, F1 +0.05~0.08\n",
    "\n",
    "2. `login_frequency_last_month` (int)\n",
    "   - ìµœê·¼ 1ê°œì›” ë¡œê·¸ì¸ íšŸìˆ˜\n",
    "   - ë‚®ìœ¼ë©´ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.03~0.05\n",
    "\n",
    "3. `days_since_last_login` (int)\n",
    "   - ë§ˆì§€ë§‰ ë¡œê·¸ì¸ ì´í›„ ê²½ê³¼ ì¼ìˆ˜\n",
    "   - ê¸¸ìˆ˜ë¡ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.04~0.06\n",
    "\n",
    "4. `skip_rate_increase_last_week` (float)\n",
    "   - ìµœê·¼ 1ì£¼ vs ì´ì „ 1ì£¼ ìŠ¤í‚µë¥  ì¦ê°€ìœ¨\n",
    "   - ì¦ê°€í•˜ë©´ ë¶ˆë§Œ ì¦ê°€ ì‹ í˜¸\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.02~0.04\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 ê³ ê° ì ‘ì  ê¸°ë¡ (ë¶ˆë§Œ/ì´íƒˆ ì‹ í˜¸)\n",
    "í˜„ì¬ ë°ì´í„°ëŠ” \"í–‰ë™ ë°ì´í„°\"ë§Œ ìˆê³ , **ê³ ê° ë¶ˆë§Œ/ë¬¸ì œ**ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì‹ í˜¸ê°€ ì—†ìŒ.\n",
    "\n",
    "**ì¶”ê°€ í•„ìš” ì»¬ëŸ¼:**\n",
    "1. `customer_support_contact` (bool)\n",
    "   - ìµœê·¼ 1ê°œì›” ë‚´ ê³ ê°ì„¼í„° ë¬¸ì˜ ì—¬ë¶€\n",
    "   - ìˆìœ¼ë©´ ë¶ˆë§Œ â†’ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.03~0.05\n",
    "\n",
    "2. `payment_failure_count` (int)\n",
    "   - ê²°ì œ ì‹¤íŒ¨ íšŸìˆ˜ (Premium/Family ìœ ì €)\n",
    "   - ë§ìœ¼ë©´ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.02~0.04\n",
    "\n",
    "3. `promotional_email_click` (bool)\n",
    "   - í”„ë¡œëª¨ì…˜ ì´ë©”ì¼ í´ë¦­ ì—¬ë¶€\n",
    "   - ì•ˆ í´ë¦­í•˜ë©´ ê´€ì‹¬ë„â†“ â†’ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.01~0.03\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 ì½˜í…ì¸  ì†Œë¹„ íŒ¨í„´\n",
    "í˜„ì¬ ë°ì´í„°ëŠ” \"ì–‘ì  ì •ë³´\"ë§Œ ìˆê³ , **ì§ˆì  ì •ë³´**(ë¬´ì—‡ì„ ë“£ëŠ”ì§€)ê°€ ì—†ìŒ.\n",
    "\n",
    "**ì¶”ê°€ í•„ìš” ì»¬ëŸ¼:**\n",
    "1. `song_diversity_score` (float)\n",
    "   - ë“£ëŠ” ê³¡ ì¥ë¥´/ì•„í‹°ìŠ¤íŠ¸ ë‹¤ì–‘ì„± (0~1)\n",
    "   - ê°ì†Œí•˜ë©´ í¥ë¯¸â†“ â†’ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.02~0.04\n",
    "\n",
    "2. `playlist_creation_count` (int)\n",
    "   - ìµœê·¼ 1ê°œì›” í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ìƒì„± íšŸìˆ˜\n",
    "   - ë‚®ìœ¼ë©´ ê´€ì—¬ë„â†“ â†’ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.02~0.03\n",
    "\n",
    "3. `favorite_genre_stability` (float)\n",
    "   - ì„ í˜¸ ì¥ë¥´ ì•ˆì •ì„± (ìµœê·¼ 3ê°œì›”)\n",
    "   - ë¶ˆì•ˆì •í•˜ë©´ íƒìƒ‰ ì¤‘ â†’ ê²½ìŸì‚¬ ì´ë™ ê°€ëŠ¥\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.01~0.02\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4 ì™¸ë¶€ ìš”ì¸ ë° ê²½ìŸ\n",
    "í˜„ì¬ ë°ì´í„°ëŠ” \"Spotify ë‚´ë¶€\"ë§Œ ë³´ê³ , **ì™¸ë¶€ ê²½ìŸ/í™˜ê²½**ì„ ì „í˜€ ë°˜ì˜ ì•ˆ í•¨.\n",
    "\n",
    "**ì¶”ê°€ í•„ìš” ì»¬ëŸ¼:**\n",
    "1. `competitor_signup_date` (datetime or bool)\n",
    "   - íƒ€ ìŒì› ì„œë¹„ìŠ¤(YouTube Music, Apple Music ë“±) ê°€ì… ë‚ ì§œ\n",
    "   - ë³‘í–‰ ì´ìš© ì‹œì‘í•˜ë©´ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.03~0.05\n",
    "\n",
    "2. `social_media_sentiment` (float, -1~1)\n",
    "   - SNSì—ì„œ Spotify ì–¸ê¸‰ ì‹œ ê°ì • ë¶„ì„ ì ìˆ˜\n",
    "   - ë¶€ì •ì ì´ë©´ ì´íƒˆ ìœ„í—˜â†‘\n",
    "   - **ê¸°ëŒ€ íš¨ê³¼**: F1 +0.01~0.02\n",
    "\n",
    "---\n",
    "\n",
    "### 4.5 ê¸°ëŒ€ íš¨ê³¼ (ì¢…í•©)\n",
    "\n",
    "**í˜„ì¬ ì„±ëŠ¥**: F1 0.415, AUC 0.531\n",
    "\n",
    "**ì»¬ëŸ¼ ì¶”ê°€ í›„ ì˜ˆìƒ ì„±ëŠ¥**:\n",
    "- ì‹œê³„ì—´ ì •ë³´ë§Œ ì¶”ê°€: **F1 0.50~0.53, AUC 0.62~0.65**\n",
    "- ê³ ê° ì ‘ì ê¹Œì§€ ì¶”ê°€: **F1 0.54~0.58, AUC 0.66~0.70**\n",
    "- ëª¨ë“  ì»¬ëŸ¼ ì¶”ê°€: **F1 0.60~0.65, AUC 0.72~0.77**\n",
    "\n",
    "**ì‹¤ë¬´ ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥**: F1 0.6+, AUC 0.7+\n",
    "\n",
    "---\n",
    "\n",
    "## 5. ìµœì¢… ìš”ì•½\n",
    "\n",
    "### í˜„ì¬ ìƒíƒœ\n",
    "- âœ… ì²´ê³„ì ì¸ FE ê²€ì¦ ë° ëª¨ë¸ íŠœë‹ ì™„ë£Œ\n",
    "- âœ… ë°ì´í„° í•œê³„ë¥¼ ìˆ˜ì¹˜ì  ê·¼ê±°ë¡œ ëª…í™•íˆ ì…ì¦\n",
    "- âœ… F1 0.415, AUC 0.531 (í˜„ ë°ì´í„° êµ¬ì¡°ì—ì„œì˜ ìµœì„ )\n",
    "\n",
    "### ê°œì„  ë°©í–¥\n",
    "- ğŸ“Š ì‹œê³„ì—´ ë°ì´í„° í™•ë³´ â†’ **í–‰ë™ ë³€í™” ì¶”ì **\n",
    "- ğŸ“ ê³ ê° ì ‘ì  ë°ì´í„° â†’ **ë¶ˆë§Œ ì‹ í˜¸ í¬ì°©**\n",
    "- ğŸµ ì½˜í…ì¸  ì†Œë¹„ íŒ¨í„´ â†’ **ì§ˆì  ì •ë³´ ì¶”ê°€**\n",
    "- ğŸŒ ì™¸ë¶€ ìš”ì¸ ë°˜ì˜ â†’ **ê²½ìŸì‚¬ ë™í–¥ íŒŒì•…**\n",
    "\n",
    "### ê¸°ëŒ€ íš¨ê³¼\n",
    "- F1 0.415 â†’ **0.60~0.65** (ì•½ 45% í–¥ìƒ)\n",
    "- AUC 0.531 â†’ **0.72~0.77** (ì•½ 35% í–¥ìƒ)\n",
    "- ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ ìˆ˜ì¤€ ë‹¬ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378e728",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
