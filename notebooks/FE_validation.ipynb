{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a3ad15",
   "metadata": {},
   "source": [
    "# FE Validation Notebook\n",
    "\n",
    "- 공통 전처리: 간단한 결측치 처리 + 현재 설계된 FE 4개 생성\n",
    "- 기본 모델: `StandardScaler + LogisticRegression(class_weight=\"balanced\")`\n",
    "- 목표: 어떤 FE 조합이 F1 / AUC 향상에 도움이 되는지 순차적으로 비교\n",
    "\n",
    "> 최종적으로 괜찮다고 판단된 FE만, 나중에 2번이 만드는 파이프라인에 반영하도록 제안하는 용도입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860b8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape = (8000, 12)\n",
      "Index(['user_id', 'gender', 'age', 'country', 'subscription_type',\n",
      "       'listening_time', 'songs_played_per_day', 'skip_rate', 'device_type',\n",
      "       'ads_listened_per_week', 'offline_listening', 'is_churned'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "DATA_PATH = \"../data/raw_data.csv\"\n",
    "\n",
    "# 원본 데이터 로드              \n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"df shape =\", df.shape)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687662f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fe_dataframe() -> pd.DataFrame:\n",
    "    \"\"\"결측치 median 처리 + 설계서 기준 FE 4개 생성한 df 반환\n",
    "    - 기존 preprocessing_validation.ipynb의 FE 생성 로직을 재사용\n",
    "    \"\"\"\n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    # 결측치 median 처리 (수치형)\n",
    "    num_cols = [\n",
    "        \"age\",\n",
    "        \"listening_time\",\n",
    "        \"songs_played_per_day\",\n",
    "        \"skip_rate\",\n",
    "        \"ads_listened_per_week\",\n",
    "        \"offline_listening\",\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in df_tmp.columns and df_tmp[c].isnull().any():\n",
    "            df_tmp[c] = df_tmp[c].fillna(df_tmp[c].median())\n",
    "\n",
    "    # FE 4개 생성\n",
    "    # 1) engagement_score\n",
    "    if {\"listening_time\", \"songs_played_per_day\"}.issubset(df_tmp.columns):\n",
    "        df_tmp[\"engagement_score\"] = (\n",
    "            df_tmp[\"listening_time\"] * df_tmp[\"songs_played_per_day\"]\n",
    "        )\n",
    "\n",
    "    # 2) listening_time_bin\n",
    "    if \"listening_time\" in df_tmp.columns:\n",
    "        try:\n",
    "            df_tmp[\"listening_time_bin\"] = pd.qcut(\n",
    "                df_tmp[\"listening_time\"], 3, labels=[\"low\", \"mid\", \"high\"]\n",
    "            )\n",
    "        except Exception:\n",
    "            bins = [0, 60, 180, df_tmp[\"listening_time\"].max()]\n",
    "            df_tmp[\"listening_time_bin\"] = pd.cut(\n",
    "                df_tmp[\"listening_time\"], bins=bins, labels=[\"low\", \"mid\", \"high\"], include_lowest=True\n",
    "            )\n",
    "\n",
    "    # 3) skip_rate_cap\n",
    "    if \"skip_rate\" in df_tmp.columns:\n",
    "        df_tmp[\"skip_rate_cap\"] = df_tmp[\"skip_rate\"].clip(lower=0, upper=1.5)\n",
    "\n",
    "    # 4) ads_pressure\n",
    "    if {\"ads_listened_per_week\", \"listening_time\"}.issubset(df_tmp.columns):\n",
    "        lt_nonzero = df_tmp[\"listening_time\"].replace(0, np.nan)\n",
    "        df_tmp[\"ads_pressure\"] = df_tmp[\"ads_listened_per_week\"] / lt_nonzero\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "def evaluate_with_logistic(feature_cols):\n",
    "    \"\"\"주어진 feature 컬럼 리스트로 LogisticRegression 성능(F1, AUC)을 계산\"\"\"\n",
    "    df_fe = make_fe_dataframe()\n",
    "\n",
    "    X = df_fe[feature_cols]\n",
    "    y = df_fe[\"is_churned\"]\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_valid)\n",
    "    y_proba = pipe.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "\n",
    "    return f1, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba48801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Set A - 기본 수치형]   F1 = 0.3320, AUC = 0.4895\n",
      "[Set B - 기본+FE 3개] F1 = 0.3351, AUC = 0.4893\n"
     ]
    }
   ],
   "source": [
    "# 기본 수치형만 사용한 Set A\n",
    "base_num = [\n",
    "    \"age\",\n",
    "    \"listening_time\",\n",
    "    \"songs_played_per_day\",\n",
    "    \"skip_rate\",\n",
    "    \"ads_listened_per_week\",\n",
    "    \"offline_listening\",\n",
    "]\n",
    "\n",
    "# 기존 FE 4개 중 수치형 3개만 (bin은 나중에 one-hot 별도 실험 예정)\n",
    "fe_num = [\"engagement_score\", \"skip_rate_cap\", \"ads_pressure\"]\n",
    "\n",
    "# Set A: 기본 수치형만\n",
    "f1_A, auc_A = evaluate_with_logistic(base_num)\n",
    "\n",
    "# Set B: 기본 수치형 + FE 3개 (ads_pressure 포함)\n",
    "fe_exist = [c for c in fe_num if c in make_fe_dataframe().columns]\n",
    "feature_cols_B = base_num + fe_exist\n",
    "f1_B, auc_B = evaluate_with_logistic(feature_cols_B)\n",
    "\n",
    "print(\"[Set A - 기본 수치형]   F1 = {:.4f}, AUC = {:.4f}\".format(f1_A, auc_A))\n",
    "print(\"[Set B - 기본+FE 3개] F1 = {:.4f}, AUC = {:.4f}\".format(f1_B, auc_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f0fc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Set C - 기본+FE 3개+bin] F1 = 0.3369, AUC = 0.4886\n"
     ]
    }
   ],
   "source": [
    "# Set C: 기본 수치형 + FE 3개 + listening_time_bin 원-핫\n",
    "df_fe = make_fe_dataframe()\n",
    "\n",
    "base_num = [\n",
    "    \"age\",\n",
    "    \"listening_time\",\n",
    "    \"songs_played_per_day\",\n",
    "    \"skip_rate\",\n",
    "    \"ads_listened_per_week\",\n",
    "    \"offline_listening\",\n",
    "]\n",
    "fe_num = [\"engagement_score\", \"skip_rate_cap\", \"ads_pressure\"]\n",
    "\n",
    "X_num = df_fe[base_num + [c for c in fe_num if c in df_fe.columns]]\n",
    "\n",
    "# listening_time_bin 원-핫\n",
    "if \"listening_time_bin\" in df_fe.columns:\n",
    "    lt_dummies = pd.get_dummies(df_fe[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True)\n",
    "    X_C = pd.concat([X_num, lt_dummies], axis=1)\n",
    "else:\n",
    "    X_C = X_num  # 혹시라도 없으면 수치형만\n",
    "\n",
    "y = df_fe[\"is_churned\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_C, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_valid)\n",
    "y_proba = pipe.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "f1_C = f1_score(y_valid, y_pred)\n",
    "auc_C = roc_auc_score(y_valid, y_proba)\n",
    "\n",
    "print(\"[Set C - 기본+FE 3개+bin] F1 = {:.4f}, AUC = {:.4f}\".format(f1_C, auc_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafd384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set A] F1 = 0.0994, AUC = 0.5241\n",
      "[RF Set B] F1 = 0.0950, AUC = 0.5355\n",
      "[RF Set C] F1 = 0.0996, AUC = 0.5375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def evaluate_with_rf(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_valid)\n",
    "    y_proba = rf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    return f1, auc\n",
    "\n",
    "df_fe = make_fe_dataframe()\n",
    "y = df_fe[\"is_churned\"]\n",
    "\n",
    "# Set A\n",
    "X_A = df_fe[base_num]\n",
    "f1_A_rf, auc_A_rf = evaluate_with_rf(X_A, y)\n",
    "\n",
    "# Set B\n",
    "fe_exist = [c for c in fe_num if c in df_fe.columns]\n",
    "X_B = df_fe[base_num + fe_exist]\n",
    "f1_B_rf, auc_B_rf = evaluate_with_rf(X_B, y)\n",
    "\n",
    "# Set C (bin 원-핫 포함)\n",
    "if \"listening_time_bin\" in df_fe.columns:\n",
    "    lt_dummies = pd.get_dummies(df_fe[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True)\n",
    "    X_num_C = df_fe[base_num + fe_exist]\n",
    "    X_C = pd.concat([X_num_C, lt_dummies], axis=1)\n",
    "else:\n",
    "    X_C = df_fe[base_num + fe_exist]\n",
    "\n",
    "f1_C_rf, auc_C_rf = evaluate_with_rf(X_C, y)\n",
    "\n",
    "print(\"[RF Set A] F1 = {:.4f}, AUC = {:.4f}\".format(f1_A_rf, auc_A_rf))\n",
    "print(\"[RF Set B] F1 = {:.4f}, AUC = {:.4f}\".format(f1_B_rf, auc_B_rf))\n",
    "print(\"[RF Set C] F1 = {:.4f}, AUC = {:.4f}\".format(f1_C_rf, auc_C_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec765a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set C] best F1 = 0.4090 @ th=0.15, AUC = 0.5375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_with_rf_best_f1(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_proba = rf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_th = 0.5\n",
    "    for th in np.linspace(0.1, 0.9, 17):\n",
    "        y_pred_th = (y_proba >= th).astype(int)\n",
    "        f1 = f1_score(y_valid, y_pred_th)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = th\n",
    "\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    return best_f1, best_th, auc\n",
    "\n",
    "# 예: Set C 기준으로 확인\n",
    "best_f1_C, best_th_C, auc_C = evaluate_with_rf_best_f1(X_C, y)\n",
    "print(\"[RF Set C] best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_C, best_th_C, auc_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e6131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set D] best F1 = 0.4117 @ th=0.10, AUC = 0.5396\n"
     ]
    }
   ],
   "source": [
    "# 1) make_fe_dataframe에 새 FE 2개 추가\n",
    "def make_fe_dataframe_v2() -> pd.DataFrame:\n",
    "    df_tmp = make_fe_dataframe().copy()\n",
    "\n",
    "    # listening_time 0 나누기 방지\n",
    "    lt_safe = df_tmp[\"listening_time\"].replace(0, np.nan)\n",
    "\n",
    "    # songs_per_minute\n",
    "    df_tmp[\"songs_per_minute\"] = (\n",
    "        df_tmp[\"songs_played_per_day\"] / lt_safe\n",
    "    ).fillna(0.0)\n",
    "\n",
    "    # skip_intensity = skip_rate * songs_played_per_day\n",
    "    df_tmp[\"skip_intensity\"] = (\n",
    "        df_tmp[\"skip_rate\"] * df_tmp[\"songs_played_per_day\"]\n",
    "    )\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "df_fe2 = make_fe_dataframe_v2()\n",
    "y2 = df_fe2[\"is_churned\"]\n",
    "\n",
    "# Set D: Set C + songs_per_minute + skip_intensity\n",
    "base_plus_fe = base_num + fe_num + [\"songs_per_minute\", \"skip_intensity\"]\n",
    "\n",
    "X_num_D = df_fe2[base_plus_fe]\n",
    "\n",
    "if \"listening_time_bin\" in df_fe2.columns:\n",
    "    lt_dummies2 = pd.get_dummies(\n",
    "        df_fe2[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True\n",
    "    )\n",
    "    X_D = pd.concat([X_num_D, lt_dummies2], axis=1)\n",
    "else:\n",
    "    X_D = X_num_D\n",
    "\n",
    "best_f1_D, best_th_D, auc_D = evaluate_with_rf_best_f1(X_D, y2)\n",
    "print(\"[RF Set D] best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_D, best_th_D, auc_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed7b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>songs_per_minute</td>\n",
       "      <td>0.134559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>engagement_score</td>\n",
       "      <td>0.132740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>skip_intensity</td>\n",
       "      <td>0.127132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listening_time</td>\n",
       "      <td>0.120712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.117470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>songs_played_per_day</td>\n",
       "      <td>0.103746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skip_rate</td>\n",
       "      <td>0.087120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>skip_rate_cap</td>\n",
       "      <td>0.085310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ads_pressure</td>\n",
       "      <td>0.038112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ads_listened_per_week</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lt_bin_mid</td>\n",
       "      <td>0.008234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>offline_listening</td>\n",
       "      <td>0.007278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lt_bin_high</td>\n",
       "      <td>0.004761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance\n",
       "9        songs_per_minute    0.134559\n",
       "6        engagement_score    0.132740\n",
       "10         skip_intensity    0.127132\n",
       "1          listening_time    0.120712\n",
       "0                     age    0.117470\n",
       "2    songs_played_per_day    0.103746\n",
       "3               skip_rate    0.087120\n",
       "7           skip_rate_cap    0.085310\n",
       "8            ads_pressure    0.038112\n",
       "4   ads_listened_per_week    0.032824\n",
       "11             lt_bin_mid    0.008234\n",
       "5       offline_listening    0.007278\n",
       "12            lt_bin_high    0.004761"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set D용 X_D, y2가 이미 위에서 만들어졌다고 가정\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_D, y2, test_size=0.2, random_state=42, stratify=y2\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feat_names = X_D.columns\n",
    "\n",
    "imp_df = pd.DataFrame({\"feature\": feat_names, \"importance\": importances})\n",
    "imp_df.sort_values(\"importance\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da94c00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set E] best F1 = 0.4106 @ th=0.15, AUC = 0.5339\n"
     ]
    }
   ],
   "source": [
    "# 중요도가 괜찮아 보이는 FE만 골라서 직접 리스트 작성\n",
    "important_fe = [\"engagement_score\", \"songs_per_minute\", \"skip_intensity\"]\n",
    "\n",
    "df_fe3 = make_fe_dataframe_v2()\n",
    "y3 = df_fe3[\"is_churned\"]\n",
    "\n",
    "# Set E: 기본 수치형 + 중요한 FE만 + bin\n",
    "X_num_E = df_fe3[base_num + important_fe]\n",
    "\n",
    "if \"listening_time_bin\" in df_fe3.columns:\n",
    "    lt_dummies3 = pd.get_dummies(\n",
    "        df_fe3[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True\n",
    "    )\n",
    "    X_E = pd.concat([X_num_E, lt_dummies3], axis=1)\n",
    "else:\n",
    "    X_E = X_num_E\n",
    "\n",
    "best_f1_E, best_th_E, auc_E = evaluate_with_rf_best_f1(X_E, y3)\n",
    "print(\"[RF Set E] best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_E, best_th_E, auc_E))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e2a4cd",
   "metadata": {},
   "source": [
    "### FE 실험 요약 (RandomForest + best F1 기준)\n",
    "\n",
    "- Set C (기본 + FE4 + bin): best F1 ≈ 0.409, AUC ≈ 0.538  \n",
    "- Set D (C + songs_per_minute + skip_intensity): best F1 ≈ 0.412, AUC ≈ 0.540  \n",
    "- Set E (중요 FE만 선택): best F1 ≈ 0.411, AUC ≈ 0.534  \n",
    "\n",
    "→ 성능/복잡도 균형 상, **최종 추천 FE 세트**:\n",
    "- base_num: age, listening_time, songs_played_per_day, skip_rate, ads_listened_per_week, offline_listening\n",
    "- fe_selected: (여기에 실제로 쓴 FE 이름들 정리)\n",
    "- 모델: RandomForest + threshold 튜닝 (약 th ≈ 0.10~0.15 구간)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da32da",
   "metadata": {},
   "source": [
    "### FE 실험 정리 및 추천 세트\n",
    "\n",
    "- **실험 기준**: `raw_data.csv` 기준, 수치형 median 대체 + 설계 FE 4개 생성 후, RandomForest + threshold 튜닝으로 Set C/D/E 비교\n",
    "- **결과 요약**: Set C/D/E 간 F1·AUC 차이는 매우 작지만, `songs_per_minute`, `skip_intensity` 추가 후(FE 확장) 성능이 미세하게 우세\n",
    "\n",
    "**실험용 추천 FE 조합**\n",
    "- **base_num**: `age`, `listening_time`, `songs_played_per_day`, `skip_rate`, `ads_listened_per_week`, `offline_listening`\n",
    "- **fe_selected(숫자형)**: `engagement_score`, `songs_per_minute`, `skip_intensity`\n",
    "- **fe_optional**: `ads_pressure` (효과는 미미하지만 해석/군집용 보조 변수), `listening_time_bin` one-hot (설명/세그먼트용)\n",
    "\n",
    "> 이 노트북에서는 **FE 후보를 거칠게 1차 랭킹**하는 용도로 사용하고,  \n",
    "> 최종 채택 여부는 `train_template.py`의 전체 파이프라인(Logistic + 범주형 + 교차검증)에서 다시 확인하는 것을 권장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa7c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3: v2 FE + 요금제/나이/광고 로그 FE 추가\n",
    "\n",
    "def make_fe_dataframe_v3() -> pd.DataFrame:\n",
    "    \"\"\"v2 FE 기반 + 아래 FE를 추가로 생성한 df 반환\n",
    "    - subscription_type_level (요금제 순서형 수치화)\n",
    "    - age_group (나이 구간)\n",
    "    - ads_listened_log (로그 변환)\n",
    "    \"\"\"\n",
    "    df_tmp = make_fe_dataframe_v2().copy()\n",
    "\n",
    "    # 1) subscription_type_level\n",
    "    if \"subscription_type\" in df_tmp.columns:\n",
    "        level_map = {\n",
    "            \"Free\": 0,\n",
    "            \"Student\": 1,\n",
    "            \"Premium\": 2,\n",
    "            \"Family\": 3,\n",
    "        }\n",
    "        df_tmp[\"subscription_type_level\"] = (\n",
    "            df_tmp[\"subscription_type\"].map(level_map).fillna(-1).astype(int)\n",
    "        )\n",
    "\n",
    "    # 2) age_group (단순 구간화)\n",
    "    if \"age\" in df_tmp.columns:\n",
    "        bins = [0, 24, 34, 44, df_tmp[\"age\"].max()]\n",
    "        labels = [\"young\", \"adult\", \"middle\", \"senior\"]\n",
    "        df_tmp[\"age_group\"] = pd.cut(\n",
    "            df_tmp[\"age\"],\n",
    "            bins=bins,\n",
    "            labels=labels,\n",
    "            include_lowest=True,\n",
    "            right=True,\n",
    "        )\n",
    "\n",
    "    # 3) ads_listened_log (로그 변환)\n",
    "    if \"ads_listened_per_week\" in df_tmp.columns:\n",
    "        df_tmp[\"ads_listened_log\"] = np.log1p(df_tmp[\"ads_listened_per_week\"])\n",
    "\n",
    "    return df_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c38ea459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set D] best F1 = 0.4117 @ th=0.10, AUC = 0.5396\n",
      "[RF Set F] best F1 = 0.4116 @ th=0.10, AUC = 0.5225\n",
      "[RF Set G] best F1 = 0.4104 @ th=0.10, AUC = 0.5209\n"
     ]
    }
   ],
   "source": [
    "# Set D (기존 best) vs Set F/G (추가 FE) 비교\n",
    "\n",
    "# v3 FE 데이터프레임 생성\n",
    "df_fe3 = make_fe_dataframe_v3()\n",
    "y3 = df_fe3[\"is_churned\"]\n",
    "\n",
    "# 기존 Set D와 최대한 동일한 구성 재현\n",
    "# base_num, fe_num, base_plus_fe 는 위 셀들에서 이미 정의되어 있다고 가정\n",
    "X_num_D3 = df_fe3[base_plus_fe]\n",
    "\n",
    "if \"listening_time_bin\" in df_fe3.columns:\n",
    "    lt_dummies3 = pd.get_dummies(\n",
    "        df_fe3[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True\n",
    "    )\n",
    "    X_D = pd.concat([X_num_D3, lt_dummies3], axis=1)\n",
    "else:\n",
    "    X_D = X_num_D3\n",
    "\n",
    "# Set F: Set D + subscription_type_level\n",
    "if \"subscription_type_level\" in df_fe3.columns:\n",
    "    X_F = pd.concat([X_D, df_fe3[[\"subscription_type_level\"]]], axis=1)\n",
    "else:\n",
    "    X_F = X_D.copy()\n",
    "\n",
    "# Set G: Set F + age_group 원-핫\n",
    "if \"age_group\" in df_fe3.columns:\n",
    "    age_dummies = pd.get_dummies(\n",
    "        df_fe3[\"age_group\"], prefix=\"age_g\", drop_first=True\n",
    "    )\n",
    "    X_G = pd.concat([X_F, age_dummies], axis=1)\n",
    "else:\n",
    "    X_G = X_F.copy()\n",
    "\n",
    "# 세 세트에 대해 RF + best F1 기준 성능 비교\n",
    "for name, X in [(\"D\", X_D), (\"F\", X_F), (\"G\", X_G)]:\n",
    "    best_f1, best_th, auc = evaluate_with_rf_best_f1(X, y3)\n",
    "    print(\n",
    "        f\"[RF Set {name}] best F1 = {best_f1:.4f} @ th={best_th:.2f}, AUC = {auc:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a9a042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba44fee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GB (Set D/F/G) ===\n",
      "[GB Set D] best F1 = 0.4111 @ th=0.10, AUC = 0.5082\n",
      "[GB Set F] best F1 = 0.4111 @ th=0.10, AUC = 0.5166\n",
      "[GB Set G] best F1 = 0.4112 @ th=0.15, AUC = 0.5122\n",
      "\n",
      "=== HGB (Set D/F/G) ===\n",
      "[HGB Set D] best F1 = 0.4122 @ th=0.10, AUC = 0.5230\n",
      "[HGB Set F] best F1 = 0.4090 @ th=0.10, AUC = 0.5028\n",
      "[HGB Set G] best F1 = 0.4074 @ th=0.10, AUC = 0.5141\n"
     ]
    }
   ],
   "source": [
    "# 다른 모델(GB, HGB)로도 Set D/F/G 성능 비교\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "def evaluate_model_best_f1(model, X, y, thresholds=None):\n",
    "    \"\"\"아무 분류 모델이나 받아서 best F1 / AUC 계산 (train/valid 8:2, stratify)\n",
    "    - model: scikit-learn 분류기 인스턴스\n",
    "    - thresholds: 탐색할 threshold 리스트 (None이면 0.1~0.9, step 0.05)\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0.1, 0.9, 17)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 예측 확률 또는 decision_function 사용\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_valid)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_score = model.decision_function(X_valid)\n",
    "    else:\n",
    "        # 점수 개념이 없으면 threshold 튜닝 불가 → 기본 predict만 사용\n",
    "        y_pred = model.predict(X_valid)\n",
    "        f1 = f1_score(y_valid, y_pred)\n",
    "        auc = roc_auc_score(y_valid, y_pred)\n",
    "        return f1, 0.5, auc\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_th = 0.5\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_score >= th).astype(int)\n",
    "        f1 = f1_score(y_valid, y_pred_th)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = th\n",
    "\n",
    "    auc = roc_auc_score(y_valid, y_score)\n",
    "    return best_f1, best_th, auc\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"GB\": GradientBoostingClassifier(random_state=42),\n",
    "    \"HGB\": HistGradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== {model_name} (Set D/F/G) ===\")\n",
    "    for name, X in [(\"D\", X_D), (\"F\", X_F), (\"G\", X_G)]:\n",
    "        best_f1, best_th, auc = evaluate_model_best_f1(model, X, y3)\n",
    "        print(\n",
    "            f\"[{model_name} Set {name}] best F1 = {best_f1:.4f} @ th={best_th:.2f}, AUC = {auc:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf12cd",
   "metadata": {},
   "source": [
    "### 모델별 성능 요약 & 최종 추천 FE 정리\n",
    "\n",
    "#### 1) LogisticRegression (StandardScaler 포함, threshold=0.5 고정)\n",
    "\n",
    "- **Set A (기본 수치형)**: F1 = 0.3320, AUC = 0.4895  \n",
    "- **Set B (A + FE 3개)**: F1 = 0.3351, AUC = 0.4893  \n",
    "- **Set C (A + FE 3개 + listening_time_bin 원-핫)**: F1 = 0.3369, AUC = 0.4886  \n",
    "→ Logistic 기준에서는 FE 추가로 **F1이 소폭 상승하지만, AUC 변화는 미미**하고 전체적으로 0.33~0.34 수준에 머뭄.\n",
    "\n",
    "#### 2) RandomForest (class_weight=\"balanced\" + threshold 튜닝)\n",
    "\n",
    "- **Set C (기본 + FE4 + bin)**: best F1 ≈ 0.4090 @ th=0.15, AUC ≈ 0.5375  \n",
    "- **Set D (Set C + songs_per_minute + skip_intensity)**: **best F1 ≈ 0.4117 @ th=0.10, AUC ≈ 0.5396**  \n",
    "- **Set E (중요 FE만 선택)**: best F1 ≈ 0.4110, AUC ≈ 0.534 근처  \n",
    "- **Set F/G (요금제·나이 FE 추가)**: F1은 거의 동일, AUC는 **오히려 감소(0.52 전후)**  \n",
    "→ RF 기준으로는 **Set D 구성이 가장 안정적으로 최고 성능(약 F1 0.412, AUC 0.54)**를 보이며, 요금제/나이 FE 추가는 도움이 되지 않음.\n",
    "\n",
    "#### 3) Gradient Boosting (GB) / HistGradientBoosting (HGB)\n",
    "\n",
    "- **GB** (기본 파라미터): Set D/F/G 모두 best F1 ≈ 0.411, AUC ≈ 0.51~0.52  \n",
    "- **HGB**:  \n",
    "  - Set D: best F1 ≈ 0.4122 @ th=0.10, AUC ≈ 0.5230  \n",
    "  - Set F/G: F1는 비슷하거나 더 낮고, AUC도 큰 개선 없음 (0.50~0.51대)  \n",
    "→ 부스팅 계열에서도 **F1은 모두 0.41대 초반에 수렴**하며, RF 대비 뚜렷한 향상은 없었음.\n",
    "\n",
    "#### 4) 종합 결론 (검증 + FE 관점)\n",
    "\n",
    "- 서로 다른 계열 모델(Logistic / RF / GB / HGB)을 사용해도 **F1은 0.41±0.01, AUC는 0.52~0.54 범위**에서만 움직임.  \n",
    "- 이는 **모델 구조보다는 데이터·피처의 한계**가 더 큰 상황이라는 의미로 해석 가능.  \n",
    "- 요금제(`subscription_type_level`), 나이 구간(`age_group`) 등의 파생변수는 **모델 성능 관점에서는 이득이 거의 없음**을 확인.\n",
    "\n",
    "---\n",
    "\n",
    "### 최종 추천 FE 세트 (모델 학습용 기준)\n",
    "\n",
    "- **기본 수치형(`base_num`)**  \n",
    "  - `age`, `listening_time`, `songs_played_per_day`, `skip_rate`, `ads_listened_per_week`, `offline_listening`\n",
    "- **핵심 추천 FE (모델 성능 기준)**  \n",
    "  - `engagement_score = listening_time * songs_played_per_day`  \n",
    "  - `songs_per_minute = songs_played_per_day / listening_time`  \n",
    "  - `skip_intensity = skip_rate * songs_played_per_day`  \n",
    "  - `skip_rate_cap` (이상치 완화용 기반 변수)\n",
    "- **보조/설명용 FE (필요 시 사용)**  \n",
    "  - `ads_pressure`, `listening_time_bin` (세그먼트/시각화용)  \n",
    "  - `subscription_type_level`, `age_group` (리포트/군집용, 성능 이득은 거의 없음)\n",
    "\n",
    "> 이 노트북의 역할: **여러 모델과 FE 조합을 검증한 결과, 위 FE 세트가 현재 데이터 기준 가장 합리적인 조합이라는 근거를 제공**하는 것.  \n",
    "> 추가 모델 실험/시각화 없이도, 위 수치 요약과 FE 리스트만으로 팀 내 공유/보고에 충분한 수준이라고 판단됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d078e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
