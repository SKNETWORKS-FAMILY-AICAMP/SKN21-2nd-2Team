{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a3ad15",
   "metadata": {},
   "source": [
    "# FE Validation Notebook\n",
    "\n",
    "이 노트북에서는 **좋은 FE(Feature Engineering)를 찾는 것**에만 집중합니다.\n",
    "\n",
    "- 공통 전처리: 간단한 결측치 처리 + 현재 설계된 FE 4개 생성\n",
    "- 기본 모델: `StandardScaler + LogisticRegression(class_weight=\"balanced\")`\n",
    "- 목표: 어떤 FE 조합이 F1 / AUC 향상에 도움이 되는지 순차적으로 비교\n",
    "\n",
    "> 최종적으로 괜찮다고 판단된 FE만, 나중에 2번이 만드는 파이프라인에 반영하도록 제안하는 용도입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860b8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape = (8000, 12)\n",
      "Index(['user_id', 'gender', 'age', 'country', 'subscription_type',\n",
      "       'listening_time', 'songs_played_per_day', 'skip_rate', 'device_type',\n",
      "       'ads_listened_per_week', 'offline_listening', 'is_churned'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "DATA_PATH = \"../data/raw_data.csv\"\n",
    "\n",
    "# 원본 데이터 로드\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"df shape =\", df.shape)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687662f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fe_dataframe() -> pd.DataFrame:\n",
    "    \"\"\"결측치 median 처리 + 설계서 기준 FE 4개 생성한 df 반환\n",
    "    - 기존 preprocessing_validation.ipynb의 FE 생성 로직을 재사용\n",
    "    \"\"\"\n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    # 결측치 median 처리 (수치형)\n",
    "    num_cols = [\n",
    "        \"age\",\n",
    "        \"listening_time\",\n",
    "        \"songs_played_per_day\",\n",
    "        \"skip_rate\",\n",
    "        \"ads_listened_per_week\",\n",
    "        \"offline_listening\",\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in df_tmp.columns and df_tmp[c].isnull().any():\n",
    "            df_tmp[c] = df_tmp[c].fillna(df_tmp[c].median())\n",
    "\n",
    "    # FE 4개 생성\n",
    "    # 1) engagement_score\n",
    "    if {\"listening_time\", \"songs_played_per_day\"}.issubset(df_tmp.columns):\n",
    "        df_tmp[\"engagement_score\"] = (\n",
    "            df_tmp[\"listening_time\"] * df_tmp[\"songs_played_per_day\"]\n",
    "        )\n",
    "\n",
    "    # 2) listening_time_bin\n",
    "    if \"listening_time\" in df_tmp.columns:\n",
    "        try:\n",
    "            df_tmp[\"listening_time_bin\"] = pd.qcut(\n",
    "                df_tmp[\"listening_time\"], 3, labels=[\"low\", \"mid\", \"high\"]\n",
    "            )\n",
    "        except Exception:\n",
    "            bins = [0, 60, 180, df_tmp[\"listening_time\"].max()]\n",
    "            df_tmp[\"listening_time_bin\"] = pd.cut(\n",
    "                df_tmp[\"listening_time\"], bins=bins, labels=[\"low\", \"mid\", \"high\"], include_lowest=True\n",
    "            )\n",
    "\n",
    "    # 3) skip_rate_cap\n",
    "    if \"skip_rate\" in df_tmp.columns:\n",
    "        df_tmp[\"skip_rate_cap\"] = df_tmp[\"skip_rate\"].clip(lower=0, upper=1.5)\n",
    "\n",
    "    # 4) ads_pressure\n",
    "    if {\"ads_listened_per_week\", \"listening_time\"}.issubset(df_tmp.columns):\n",
    "        lt_nonzero = df_tmp[\"listening_time\"].replace(0, np.nan)\n",
    "        df_tmp[\"ads_pressure\"] = df_tmp[\"ads_listened_per_week\"] / lt_nonzero\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "def evaluate_with_logistic(feature_cols):\n",
    "    \"\"\"주어진 feature 컬럼 리스트로 LogisticRegression 성능(F1, AUC)을 계산\"\"\"\n",
    "    df_fe = make_fe_dataframe()\n",
    "\n",
    "    X = df_fe[feature_cols]\n",
    "    y = df_fe[\"is_churned\"]\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_valid)\n",
    "    y_proba = pipe.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "\n",
    "    return f1, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba48801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Set A - 기본 수치형]   F1 = 0.3320, AUC = 0.4895\n",
      "[Set B - 기본+FE 3개] F1 = 0.3351, AUC = 0.4893\n"
     ]
    }
   ],
   "source": [
    "# 기본 수치형만 사용한 Set A\n",
    "base_num = [\n",
    "    \"age\",\n",
    "    \"listening_time\",\n",
    "    \"songs_played_per_day\",\n",
    "    \"skip_rate\",\n",
    "    \"ads_listened_per_week\",\n",
    "    \"offline_listening\",\n",
    "]\n",
    "\n",
    "# 기존 FE 4개 중 수치형 3개만 (bin은 나중에 one-hot 별도 실험 예정)\n",
    "fe_num = [\"engagement_score\", \"skip_rate_cap\", \"ads_pressure\"]\n",
    "\n",
    "# Set A: 기본 수치형만\n",
    "f1_A, auc_A = evaluate_with_logistic(base_num)\n",
    "\n",
    "# Set B: 기본 수치형 + FE 3개 (ads_pressure 포함)\n",
    "fe_exist = [c for c in fe_num if c in make_fe_dataframe().columns]\n",
    "feature_cols_B = base_num + fe_exist\n",
    "f1_B, auc_B = evaluate_with_logistic(feature_cols_B)\n",
    "\n",
    "print(\"[Set A - 기본 수치형]   F1 = {:.4f}, AUC = {:.4f}\".format(f1_A, auc_A))\n",
    "print(\"[Set B - 기본+FE 3개] F1 = {:.4f}, AUC = {:.4f}\".format(f1_B, auc_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f0fc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Set C - 기본+FE 3개+bin] F1 = 0.3369, AUC = 0.4886\n"
     ]
    }
   ],
   "source": [
    "# Set C: 기본 수치형 + FE 3개 + listening_time_bin 원-핫\n",
    "df_fe = make_fe_dataframe()\n",
    "\n",
    "base_num = [\n",
    "    \"age\",\n",
    "    \"listening_time\",\n",
    "    \"songs_played_per_day\",\n",
    "    \"skip_rate\",\n",
    "    \"ads_listened_per_week\",\n",
    "    \"offline_listening\",\n",
    "]\n",
    "fe_num = [\"engagement_score\", \"skip_rate_cap\", \"ads_pressure\"]\n",
    "\n",
    "X_num = df_fe[base_num + [c for c in fe_num if c in df_fe.columns]]\n",
    "\n",
    "# listening_time_bin 원-핫\n",
    "if \"listening_time_bin\" in df_fe.columns:\n",
    "    lt_dummies = pd.get_dummies(df_fe[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True)\n",
    "    X_C = pd.concat([X_num, lt_dummies], axis=1)\n",
    "else:\n",
    "    X_C = X_num  # 혹시라도 없으면 수치형만\n",
    "\n",
    "y = df_fe[\"is_churned\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_C, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_valid)\n",
    "y_proba = pipe.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "f1_C = f1_score(y_valid, y_pred)\n",
    "auc_C = roc_auc_score(y_valid, y_proba)\n",
    "\n",
    "print(\"[Set C - 기본+FE 3개+bin] F1 = {:.4f}, AUC = {:.4f}\".format(f1_C, auc_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bafd384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set A] F1 = 0.0994, AUC = 0.5241\n",
      "[RF Set B] F1 = 0.0950, AUC = 0.5355\n",
      "[RF Set C] F1 = 0.0996, AUC = 0.5375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def evaluate_with_rf(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_valid)\n",
    "    y_proba = rf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    return f1, auc\n",
    "\n",
    "df_fe = make_fe_dataframe()\n",
    "y = df_fe[\"is_churned\"]\n",
    "\n",
    "# Set A\n",
    "X_A = df_fe[base_num]\n",
    "f1_A_rf, auc_A_rf = evaluate_with_rf(X_A, y)\n",
    "\n",
    "# Set B\n",
    "fe_exist = [c for c in fe_num if c in df_fe.columns]\n",
    "X_B = df_fe[base_num + fe_exist]\n",
    "f1_B_rf, auc_B_rf = evaluate_with_rf(X_B, y)\n",
    "\n",
    "# Set C (bin 원-핫 포함)\n",
    "if \"listening_time_bin\" in df_fe.columns:\n",
    "    lt_dummies = pd.get_dummies(df_fe[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True)\n",
    "    X_num_C = df_fe[base_num + fe_exist]\n",
    "    X_C = pd.concat([X_num_C, lt_dummies], axis=1)\n",
    "else:\n",
    "    X_C = df_fe[base_num + fe_exist]\n",
    "\n",
    "f1_C_rf, auc_C_rf = evaluate_with_rf(X_C, y)\n",
    "\n",
    "print(\"[RF Set A] F1 = {:.4f}, AUC = {:.4f}\".format(f1_A_rf, auc_A_rf))\n",
    "print(\"[RF Set B] F1 = {:.4f}, AUC = {:.4f}\".format(f1_B_rf, auc_B_rf))\n",
    "print(\"[RF Set C] F1 = {:.4f}, AUC = {:.4f}\".format(f1_C_rf, auc_C_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec765a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set C] best F1 = 0.4090 @ th=0.15, AUC = 0.5375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_with_rf_best_f1(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_proba = rf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_th = 0.5\n",
    "    for th in np.linspace(0.1, 0.9, 17):\n",
    "        y_pred_th = (y_proba >= th).astype(int)\n",
    "        f1 = f1_score(y_valid, y_pred_th)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = th\n",
    "\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    return best_f1, best_th, auc\n",
    "\n",
    "# 예: Set C 기준으로 확인\n",
    "best_f1_C, best_th_C, auc_C = evaluate_with_rf_best_f1(X_C, y)\n",
    "print(\"[RF Set C] best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_C, best_th_C, auc_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52e6131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set D] best F1 = 0.4117 @ th=0.10, AUC = 0.5396\n"
     ]
    }
   ],
   "source": [
    "# 1) make_fe_dataframe에 새 FE 2개 추가\n",
    "def make_fe_dataframe_v2() -> pd.DataFrame:\n",
    "    df_tmp = make_fe_dataframe().copy()\n",
    "\n",
    "    # listening_time 0 나누기 방지\n",
    "    lt_safe = df_tmp[\"listening_time\"].replace(0, np.nan)\n",
    "\n",
    "    # songs_per_minute\n",
    "    df_tmp[\"songs_per_minute\"] = (\n",
    "        df_tmp[\"songs_played_per_day\"] / lt_safe\n",
    "    ).fillna(0.0)\n",
    "\n",
    "    # skip_intensity = skip_rate * songs_played_per_day\n",
    "    df_tmp[\"skip_intensity\"] = (\n",
    "        df_tmp[\"skip_rate\"] * df_tmp[\"songs_played_per_day\"]\n",
    "    )\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "df_fe2 = make_fe_dataframe_v2()\n",
    "y2 = df_fe2[\"is_churned\"]\n",
    "\n",
    "# Set D: Set C + songs_per_minute + skip_intensity\n",
    "base_plus_fe = base_num + fe_num + [\"songs_per_minute\", \"skip_intensity\"]\n",
    "\n",
    "X_num_D = df_fe2[base_plus_fe]\n",
    "\n",
    "if \"listening_time_bin\" in df_fe2.columns:\n",
    "    lt_dummies2 = pd.get_dummies(\n",
    "        df_fe2[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True\n",
    "    )\n",
    "    X_D = pd.concat([X_num_D, lt_dummies2], axis=1)\n",
    "else:\n",
    "    X_D = X_num_D\n",
    "\n",
    "best_f1_D, best_th_D, auc_D = evaluate_with_rf_best_f1(X_D, y2)\n",
    "print(\"[RF Set D] best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_D, best_th_D, auc_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ed7b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>songs_per_minute</td>\n",
       "      <td>0.134559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>engagement_score</td>\n",
       "      <td>0.132740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>skip_intensity</td>\n",
       "      <td>0.127132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listening_time</td>\n",
       "      <td>0.120712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.117470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>songs_played_per_day</td>\n",
       "      <td>0.103746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skip_rate</td>\n",
       "      <td>0.087120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>skip_rate_cap</td>\n",
       "      <td>0.085310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ads_pressure</td>\n",
       "      <td>0.038112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ads_listened_per_week</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lt_bin_mid</td>\n",
       "      <td>0.008234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>offline_listening</td>\n",
       "      <td>0.007278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lt_bin_high</td>\n",
       "      <td>0.004761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance\n",
       "9        songs_per_minute    0.134559\n",
       "6        engagement_score    0.132740\n",
       "10         skip_intensity    0.127132\n",
       "1          listening_time    0.120712\n",
       "0                     age    0.117470\n",
       "2    songs_played_per_day    0.103746\n",
       "3               skip_rate    0.087120\n",
       "7           skip_rate_cap    0.085310\n",
       "8            ads_pressure    0.038112\n",
       "4   ads_listened_per_week    0.032824\n",
       "11             lt_bin_mid    0.008234\n",
       "5       offline_listening    0.007278\n",
       "12            lt_bin_high    0.004761"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set D용 X_D, y2가 이미 위에서 만들어졌다고 가정\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_D, y2, test_size=0.2, random_state=42, stratify=y2\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feat_names = X_D.columns\n",
    "\n",
    "imp_df = pd.DataFrame({\"feature\": feat_names, \"importance\": importances})\n",
    "imp_df.sort_values(\"importance\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da94c00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF Set E] best F1 = 0.4106 @ th=0.15, AUC = 0.5339\n"
     ]
    }
   ],
   "source": [
    "# 중요도가 괜찮아 보이는 FE만 골라서 직접 리스트 작성\n",
    "important_fe = [\"engagement_score\", \"songs_per_minute\", \"skip_intensity\"]\n",
    "\n",
    "df_fe3 = make_fe_dataframe_v2()\n",
    "y3 = df_fe3[\"is_churned\"]\n",
    "\n",
    "# Set E: 기본 수치형 + 중요한 FE만 + bin\n",
    "X_num_E = df_fe3[base_num + important_fe]\n",
    "\n",
    "if \"listening_time_bin\" in df_fe3.columns:\n",
    "    lt_dummies3 = pd.get_dummies(\n",
    "        df_fe3[\"listening_time_bin\"], prefix=\"lt_bin\", drop_first=True\n",
    "    )\n",
    "    X_E = pd.concat([X_num_E, lt_dummies3], axis=1)\n",
    "else:\n",
    "    X_E = X_num_E\n",
    "\n",
    "best_f1_E, best_th_E, auc_E = evaluate_with_rf_best_f1(X_E, y3)\n",
    "print(\"[RF Set E] best F1 = {:.4f} @ th={:.2f}, AUC = {:.4f}\".format(best_f1_E, best_th_E, auc_E))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e2a4cd",
   "metadata": {},
   "source": [
    "### FE 실험 요약 (RandomForest + best F1 기준)\n",
    "\n",
    "- Set C (기본 + FE4 + bin): best F1 ≈ 0.409, AUC ≈ 0.538  \n",
    "- Set D (C + songs_per_minute + skip_intensity): best F1 ≈ 0.412, AUC ≈ 0.540  \n",
    "- Set E (중요 FE만 선택): best F1 ≈ 0.411, AUC ≈ 0.534  \n",
    "\n",
    "→ 성능/복잡도 균형 상, **최종 추천 FE 세트**:\n",
    "- base_num: age, listening_time, songs_played_per_day, skip_rate, ads_listened_per_week, offline_listening\n",
    "- fe_selected: (여기에 실제로 쓴 FE 이름들 정리)\n",
    "- 모델: RandomForest + threshold 튜닝 (약 th ≈ 0.10~0.15 구간)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
